{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # type: ignore\n",
    "import os\n",
    "from tensorflow.keras.models import Model, load_model # type: ignore\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Reshape, Conv2DTranspose, Add, LeakyReLU, UpSampling2D, Dropout, Concatenate, AveragePooling2D, GlobalMaxPooling2D, Lambda, ZeroPadding2D  # type: ignore\n",
    "from keras.initializers import glorot_uniform # type: ignore\n",
    "from tensorflow.keras.optimizers import SGD, Adam # type: ignore\n",
    "from tensorflow.keras.regularizers import l2 # type: ignore\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay # type: ignore\n",
    "from tensorflow.keras.losses import MeanSquaredError, CategoricalCrossentropy, MeanAbsoluteError # type: ignore\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "import keras_tuner as kt # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3985 images belonging to 21 classes.\n",
      "Found 199 images belonging to 21 classes.\n",
      "Found 4231 images belonging to 22 classes.\n",
      "Found 212 images belonging to 22 classes.\n",
      "Found 4160 images belonging to 21 classes.\n",
      "Found 208 images belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "# Fonction qui genere des vecteurs aleatoires\n",
    "def generate_unique_vectors(num_vectors, vector_length, vectors):\n",
    "    vectors_list = []\n",
    "    while len(vectors_list) < num_vectors:\n",
    "        vector = tuple(np.random.randint(0, 2, vector_length))\n",
    "        if vector not in vectors:\n",
    "            vectors.add(vector)\n",
    "            vectors_list.append(vector)\n",
    "    return vectors_list, vectors\n",
    "\n",
    "# Fonction qui convertie le generateur en tableau numpy\n",
    "def generator_to_array(generator, class_vectors):\n",
    "    samples = []\n",
    "    vectors = []\n",
    "    data_filenames = generator.filenames\n",
    "    total_images = len(data_filenames)\n",
    "\n",
    "    for i in range(len(generator)):\n",
    "        batch = next(generator)\n",
    "        batch_size = len(batch[0])\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            index = i * generator.batch_size + j\n",
    "            if index >= total_images:\n",
    "                break  # Prevent going out of bounds\n",
    "\n",
    "            samples.append(batch[0][j])\n",
    "            class_name = data_filenames[index].split(os.path.sep)[0]\n",
    "            vectors.append(class_vectors[class_name])\n",
    "            \n",
    "    return np.array(samples), np.array(vectors), data_filenames\n",
    "\n",
    "# Fonction qui associe les images aux labels\n",
    "def preprocess(train_generator, val_generator, num_classes, vector_length, total_vectors, use_random_vectors):\n",
    "    class_indices = train_generator.class_indices\n",
    "    \n",
    "    if use_random_vectors:\n",
    "        unique_vectors, total_vectors = generate_unique_vectors(num_classes, vector_length, total_vectors)\n",
    "        class_vectors = {class_name: vector for class_name, vector in zip(class_indices, unique_vectors)}\n",
    "    else:\n",
    "        class_vectors = {class_name: i for i, class_name in enumerate(class_indices)}\n",
    "    \n",
    "    samples_train, vectors_train, _ = generator_to_array(train_generator, class_vectors)\n",
    "    samples_val, vectors_val, _ = generator_to_array(val_generator, class_vectors)\n",
    "    \n",
    "    if not use_random_vectors:\n",
    "        # Convert class indices to one-hot encoding\n",
    "        vectors_train = to_categorical(vectors_train, num_classes=num_classes)\n",
    "        vectors_val = to_categorical(vectors_val, num_classes=num_classes)\n",
    "    \n",
    "    return samples_train, vectors_train, samples_val, vectors_val, total_vectors\n",
    "\n",
    "# Fonction qui charge les donnees\n",
    "def load_data(datagen, target_size=(150, 150), batch_size=112, class_mode='input', shuffle=False, color_mode='grayscale', use_random_vectors=True, vector_length=56):\n",
    "    ethnies = {'caucasians': [], 'afro_americans': [], 'asians': []}\n",
    "    total_vectors = set()\n",
    "    #check = True\n",
    "    for ethnie in ethnies.keys():\n",
    "        trainset = datagen.flow_from_directory(f'../../Datasets/VGG/{ethnie}', target_size=target_size, batch_size=batch_size, class_mode=class_mode, shuffle=shuffle, color_mode=color_mode, subset='training')\n",
    "        testset  = datagen.flow_from_directory(f'../../Datasets/VGG/{ethnie}', target_size=target_size, batch_size=batch_size, class_mode=class_mode, shuffle=shuffle, color_mode=color_mode, subset='validation')\n",
    "        \n",
    "        # Number of classes for one-hot encoding\n",
    "        num_classes = len(trainset.class_indices)\n",
    "        \n",
    "        samples_train, vectors_train, samples_val, vectors_val, total_vectors = preprocess(trainset, testset, num_classes, vector_length, total_vectors, use_random_vectors)\n",
    "        \n",
    "        \"\"\" if trainset.n != samples_train.shape[0] or testset.n != samples_val.shape[0]: check = False \"\"\"\n",
    "        ethnies[ethnie] = [trainset, testset, samples_train, vectors_train, samples_val, vectors_val]\n",
    "    #print(check)\n",
    "    return ethnies\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.05, dtype='float16')\n",
    "\n",
    "ethnies = load_data(datagen, target_size=(300, 300), color_mode='grayscale', use_random_vectors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(inputs, cardinality):\n",
    "    inputs_channels = inputs.shape[3]\n",
    "    group_size = inputs_channels // cardinality    \n",
    "    groups = list()\n",
    "    for number in range(1, cardinality+1):\n",
    "        begin = int((number-1)*group_size)\n",
    "        end = int(number*group_size)\n",
    "        block = Lambda(lambda x:x[:,:,:,begin:end])(inputs)\n",
    "        groups.append(block)\n",
    "    return groups\n",
    "\n",
    "def transform(groups, filters, strides, stage, block, downsampling):\n",
    "    f1, f2 = filters    \n",
    "    conv_name = \"conv2d-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    bn_name = \"batchnorm-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    \n",
    "    transformed_tensor = list()\n",
    "    i = 1\n",
    "    \n",
    "    for inputs in groups:\n",
    "        # first conv of the transformation phase\n",
    "        x = Conv2D(filters=f1, kernel_size=(1,1), padding=\"valid\", \n",
    "                   kernel_initializer=glorot_uniform(seed=0))(inputs) #name=conv_name+'1a_split'+str(i), \n",
    "        if downsampling:\n",
    "            x = MaxPooling2D(2)(x)\n",
    "        x = BatchNormalization(axis=3)(x) #name=bn_name+'1a_split'+str(i)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        # second conv of the transformation phase\n",
    "        x = Conv2D(filters=f2, kernel_size=(3,3), strides=(1,1), padding=\"same\", \n",
    "                   kernel_initializer=glorot_uniform(seed=0))(x) #name=conv_name+'1b_split'+str(i), \n",
    "        x = BatchNormalization(axis=3)(x) #name=bn_name+'1b_split'+str(i)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        # Add x to transformed tensor list\n",
    "        transformed_tensor.append(x)\n",
    "        i+=1\n",
    "        \n",
    "    # Concatenate all tensor from each group\n",
    "    x = Concatenate()(transformed_tensor)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def transition(inputs, filters, stage, block):\n",
    "    x = Conv2D(filters=filters, kernel_size=(1,1), strides=(1,1), padding=\"valid\", \n",
    "                   kernel_initializer=glorot_uniform(seed=0))(inputs) #name='conv2d-trans'+str(stage)+''+block, \n",
    "    x = BatchNormalization(axis=3)(x) #name='batchnorm-trans'+str(stage)+''+block\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(inputs, filters, cardinality, stage, block, strides=(1,1)):    \n",
    "    identity = True\n",
    "\n",
    "    conv_name = \"conv2d-{stage}{block}-branch\".format(stage=str(stage),block=str(block))\n",
    "    bn_name = \"batchnorm-{stage}{block}-branch\".format(stage=str(stage),block=str(block))\n",
    "    \n",
    "    #save the input tensor value\n",
    "    x_shortcut = inputs\n",
    "    x = inputs\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    # divide input channels into groups. The number of groups is define by cardinality param\n",
    "    groups = split(inputs=x, cardinality=cardinality)\n",
    "    \n",
    "    # transform each group by doing a set of convolutions and concat the results\n",
    "    f1 = int(f1 / cardinality)\n",
    "    f2 = int(f2 / cardinality)\n",
    "    x = transform(groups=groups, filters=(f1, f2), strides=strides, stage=stage, block=block, downsampling=False)\n",
    "    # make a transition by doing 1x1 conv\n",
    "    x = transition(inputs=x, filters=f3, stage=stage, block=block)\n",
    "    # Last step of the identity block, shortcut concatenation\n",
    "    x = Add()([x,x_shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    print(x.shape)\n",
    "    return x\n",
    "\n",
    "def downsampling(inputs, filters, cardinality, strides, stage, block):    \n",
    "    # useful variables\n",
    "    conv_name = \"conv2d-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    bn_name = \"batchnorm-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    \n",
    "    # Retrieve filters for each layer\n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    # save the input tensor value\n",
    "    x_shortcut = inputs\n",
    "    x = inputs\n",
    "    \n",
    "    # divide input channels into groups. The number of groups is define by cardinality param\n",
    "    groups = split(inputs=x, cardinality=cardinality)\n",
    "    \n",
    "    # transform each group by doing a set of convolutions and concat the results\n",
    "    f1 = int(f1 / cardinality)\n",
    "    f2 = int(f2 / cardinality)\n",
    "    x = transform(groups=groups, filters=(f1, f2), strides=strides, stage=stage, block=block, downsampling=True)\n",
    "    print(x.shape, 'transfo downsampling')\n",
    "    # make a transition by doing 1x1 conv\n",
    "    x = transition(inputs=x, filters=f3, stage=stage, block=block)\n",
    "    print(x.shape, 'transi downsampling')\n",
    "    # Projection Shortcut to match dimensions \n",
    "    x_shortcut = Conv2D(filters=f3, kernel_size=(1,1), padding=\"valid\",\n",
    "               kernel_initializer=glorot_uniform(seed=0))(x_shortcut) #name='{base}2'.format(base=conv_name),\n",
    "    x_shortcut = MaxPooling2D(2)(x_shortcut)\n",
    "    x_shortcut = BatchNormalization(axis=3)(x_shortcut) #, name='{base}2'.format(base=bn_name)\n",
    "    #print(x.shape, x_shortcut.shape)\n",
    "    # Add x and x_shortcut\n",
    "    x = Add()([x,x_shortcut])\n",
    "    #print(x.shape)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_decoder(groups, filters, strides, stage, block):\n",
    "    conv_name = \"transpo_conv2d-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    bn_name = \"transpo_batchnorm-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    \n",
    "    transformed_tensor = []\n",
    "    f1, f2 = filters\n",
    "    i = 1\n",
    "    \n",
    "    for inputs in groups:\n",
    "        # first conv transpose of the transformation phase\n",
    "        x = Conv2DTranspose(filters=f1, kernel_size=(1,1), strides=(1,1), padding=\"same\", \n",
    "                            kernel_initializer=glorot_uniform(seed=0))(inputs) #name=conv_name+'2a_split'+str(i),\n",
    "        x = BatchNormalization(axis=3)(x) #name=bn_name+'2a_split'+str(i)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        # second conv transpose of the transformation phase\n",
    "        x = Conv2DTranspose(filters=f2, kernel_size=(3,3), strides=strides, padding=\"same\", \n",
    "                            kernel_initializer=glorot_uniform(seed=0))(x) #name=conv_name+'2b_split'+str(i), \n",
    "        x = BatchNormalization(axis=3)(x) #name=bn_name+'2b_split'+str(i)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        transformed_tensor.append(x)\n",
    "        i += 1\n",
    "        \n",
    "    x = Concatenate()(transformed_tensor)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def transition_decoder(inputs, filters, stage, block):\n",
    "    conv_name = \"transpo_conv2d-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    bn_name = \"transpo_batchnorm-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    \n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=(1,1), strides=(1,1), padding=\"valid\", \n",
    "                        kernel_initializer=glorot_uniform(seed=0))(inputs) #name=conv_name+'2',\n",
    "    x = BatchNormalization(axis=3)(x) #, name=bn_name+'2')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def identity_block_decoder(inputs, filters, cardinality, stage, block, strides=(1,1)):\n",
    "    conv_name = \"conv2d-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    bn_name = \"batchnorm-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    \n",
    "    # Sauvegarder la valeur du tenseur d'entrée\n",
    "    x_shortcut = inputs\n",
    "    x = inputs\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    # Diviser les canaux d'entrée en groupes. Le nombre de groupes est défini par le paramètre cardinalité\n",
    "    groups = split(inputs=x, cardinality=cardinality)\n",
    "    \n",
    "    # Transformer chaque groupe en faisant un ensemble de convolutions transposées et concaténer les résultats\n",
    "    f1 = int(f1 / cardinality)\n",
    "    f2 = int(f2 / cardinality)\n",
    "    x = transform_decoder(groups=groups, filters=(f1, f2), strides=strides, stage=stage, block=block)\n",
    "    \n",
    "    # Faire une transition en utilisant 1x1 conv transposée\n",
    "    x = transition_decoder(inputs=x, filters=f3, stage=stage, block=block)\n",
    "    \n",
    "    # Dernière étape du bloc d'identité, concaténation du raccourci\n",
    "    x = Add()([x, x_shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def upsampling(inputs, filters, cardinality, strides, stage, block):\n",
    "    # Variables utiles\n",
    "    conv_name = \"transpo_conv2d-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    bn_name = \"transpo_batchnorm-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    \n",
    "    # Récupérer les filtres pour chaque couche\n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    # Sauvegarder la valeur du tenseur d'entrée\n",
    "    x_shortcut = inputs\n",
    "    x = inputs\n",
    "    \n",
    "    # Diviser les canaux d'entrée en groupes. Le nombre de groupes est défini par le paramètre cardinalité\n",
    "    groups = split(inputs=x, cardinality=cardinality)\n",
    "    \n",
    "    # Transformer chaque groupe en faisant un ensemble de convolutions transposées et concaténer les résultats\n",
    "    f1 = int(f1 / cardinality)\n",
    "    f2 = int(f2 / cardinality)\n",
    "    x = transform_decoder(groups=groups, filters=(f1, f2), strides=strides, stage=stage, block=block)\n",
    "    print(x.shape, 'transfo')\n",
    "    # Faire une transition en utilisant 1x1 conv transposée\n",
    "    x = transition_decoder(inputs=x, filters=f3, stage=stage, block=block)\n",
    "    print(x.shape, 'transi')\n",
    "    # Projection du raccourci pour correspondre aux dimensions\n",
    "    x_shortcut = Conv2DTranspose(filters=f3, kernel_size=(1,1), strides=strides, padding=\"valid\", \n",
    "                                 kernel_initializer=glorot_uniform(seed=0))(x_shortcut) #name='{base}2'.format(base=conv_name), \n",
    "    x_shortcut = BatchNormalization(axis=3)(x_shortcut) #, name='{base}2'.format(base=bn_name))(x_shortcut)\n",
    "    \n",
    "    # Ajouter x et x_shortcut\n",
    "    x = Add()([x, x_shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNeXt50_AutoEncoder(input_shape, input_latent):\n",
    "    # Transform input to a tensor of shape input_shape\n",
    "    x_input = Input(input_shape)\n",
    "    \n",
    "    # Add zero padding\n",
    "    x = ZeroPadding2D((3, 3))(x_input)\n",
    "    \n",
    "    # Initial Stage (Encoder)\n",
    "    x = Conv2D(filters=128, kernel_size=(5, 5), kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis=3, name='batchnorm_1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    filters = [256, 256, 512, 512, 1024]\n",
    "\n",
    "    for filter in filters:\n",
    "        x = downsampling(inputs=x, filters=(filter, filter, filter*2), cardinality=128, strides=(2, 2), stage=1, block=\"a\")\n",
    "        print(x.shape, \" en dehors de la f down\")\n",
    "        \"\"\" \n",
    "        x = identity_block(inputs=x, filters=(filter, filter, filter*2), cardinality=32, stage=1, block=\"b\")\n",
    "        x = identity_block(inputs=x, filters=(filter, filter, filter*2), cardinality=32, stage=1, block=\"c\") \"\"\"\n",
    "\n",
    "    x = Conv2D(filters=1024, kernel_size=(1, 1), kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(filters=2048, kernel_size=(1, 1), kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    print(x.shape, 'dernière reduc')\n",
    "    # Stage 2 (Encoder)\n",
    "    \n",
    "    # Bottleneck\n",
    "    x = Conv2D(input_latent, 2, padding='same', use_bias=False)(x)\n",
    "    x = Flatten()(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    # Latent space\n",
    "    latent_space_layer = Dense(input_latent, activation='relu', use_bias=False)(x)\n",
    "    latent_space_layer_norm = BatchNormalization(name='latent_space_layer_norm')(latent_space_layer)\n",
    "\n",
    "    # Reconstruction\n",
    "    reshape_layer = Reshape(target_shape=(1, 1, input_latent))(latent_space_layer_norm)\n",
    "    x_recon = Conv2DTranspose(input_latent, 3, strides=1, padding='same', use_bias=False)(reshape_layer)\n",
    "    \n",
    "    print(x_recon.shape)\n",
    "    # Stage 5 (Decoder)\n",
    "\n",
    "    x_recon = Conv2DTranspose(filters=2048, kernel_size=(3,3), strides=1)(x_recon)\n",
    "    x_recon = BatchNormalization(axis=3)(x_recon)\n",
    "    x_recon = Activation('relu')(x_recon)\n",
    "    x_recon = Conv2DTranspose(filters=1024, kernel_size=(3, 3), strides=1)(x_recon)\n",
    "    x_recon = BatchNormalization(axis=3)(x_recon)\n",
    "    x_recon = Activation('relu')(x_recon)\n",
    "\n",
    "    for filter in reversed(filters):\n",
    "        x_recon = upsampling(inputs=x_recon, filters=(filter*2, filter*2, filter), cardinality=128, strides=(2, 2), stage=5, block=\"a\")\n",
    "        print(x_recon.shape)\n",
    "        \"\"\" \n",
    "        x_recon = identity_block_decoder(inputs=x_recon, filters=(filter*2, filter*2, filter), cardinality=32, stage=5, block=\"b\")\n",
    "        x_recon = identity_block_decoder(inputs=x_recon, filters=(filter*2, filter*2, filter), cardinality=32, stage=5, block=\"c\") \"\"\"\n",
    "        \n",
    "    x_recon = upsampling(inputs=x_recon, filters=(filter*2, filter*2, filter), cardinality=128, strides=(2, 2), stage=5, block=\"a\")\n",
    "    print(x_recon.shape)\n",
    "    # Final Convolution to reconstruct the image    \n",
    "    x_recon = Conv2DTranspose(1, (1, 1), padding='same', activation='sigmoid')(x_recon)\n",
    "    x_recon = tf.keras.layers.Resizing(height=input_shape[0], width=input_shape[1], name='recon_image')(x_recon)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=x_input, outputs=x_recon, name=\"resnext50_autoencoder\")\n",
    "    \n",
    "    lr_schedule = ExponentialDecay(initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9, staircase=True)\n",
    "    optimizer = SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "    model.compile(optimizer=optimizer, loss=MeanSquaredError())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 151, 151, 128)\n",
      "(None, 75, 75, 256) transfo downsampling\n",
      "(None, 75, 75, 512) transi downsampling\n",
      "(None, 75, 75, 512)  en dehors de la f down\n",
      "(None, 37, 37, 256) transfo downsampling\n",
      "(None, 37, 37, 512) transi downsampling\n",
      "(None, 37, 37, 512)  en dehors de la f down\n",
      "(None, 18, 18, 512) transfo downsampling\n",
      "(None, 18, 18, 1024) transi downsampling\n",
      "(None, 18, 18, 1024)  en dehors de la f down\n",
      "(None, 9, 9, 512) transfo downsampling\n",
      "(None, 9, 9, 1024) transi downsampling\n",
      "(None, 9, 9, 1024)  en dehors de la f down\n",
      "(None, 4, 4, 1024) transfo downsampling\n",
      "(None, 4, 4, 2048) transi downsampling\n",
      "(None, 4, 4, 2048)  en dehors de la f down\n",
      "(None, 1, 1, 2048) dernière reduc\n",
      "(None, 512)\n",
      "(None, 1, 1, 512)\n",
      "(None, 10, 10, 2048) transfo\n",
      "(None, 10, 10, 1024) transi\n",
      "(None, 10, 10, 1024)\n",
      "(None, 20, 20, 1024) transfo\n",
      "(None, 20, 20, 512) transi\n",
      "(None, 20, 20, 512)\n",
      "(None, 40, 40, 1024) transfo\n",
      "(None, 40, 40, 512) transi\n",
      "(None, 40, 40, 512)\n",
      "(None, 80, 80, 512) transfo\n",
      "(None, 80, 80, 256) transi\n",
      "(None, 80, 80, 256)\n",
      "(None, 160, 160, 512) transfo\n",
      "(None, 160, 160, 256) transi\n",
      "(None, 160, 160, 256)\n",
      "(None, 320, 320, 512) transfo\n",
      "(None, 320, 320, 256) transi\n",
      "(None, 320, 320, 256)\n"
     ]
    }
   ],
   "source": [
    "# Testing the model creation\n",
    "model = ResNeXt50_AutoEncoder(input_shape=(300, 300, 1), input_latent=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "ethnie = 'caucasians'\n",
    "x_train = ethnies[ethnie][2]\n",
    "x_val = ethnies[ethnie][4]\n",
    "x_print = x_val.copy()\n",
    "np.random.shuffle(x_print)\n",
    "x_print = x_print[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 46\u001b[0m\n\u001b[0;32m     36\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[0;32m     37\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResults/weights/Resnext_best_weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     38\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     save_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Model Training\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mCustomCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_print\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\envs\\envguilhem\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\envs\\envguilhem\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# Custom Callback Definition\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_data, display_loss_interval=10, display_recon_interval=20):\n",
    "        super().__init__()\n",
    "        self.test_data = test_data\n",
    "        self.display_loss_interval = display_loss_interval\n",
    "        self.display_recon_interval = display_recon_interval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.display_recon_interval == 0:\n",
    "            reconstructions = self.model.predict(self.test_data, verbose=0)\n",
    "            self.display_reconstruction(epoch+1, self.test_data, reconstructions)\n",
    "        if epoch % self.display_loss_interval == 0:\n",
    "            print(f\"Epoch {epoch+1}, Loss: {logs['loss']:.4g}\")\n",
    "\n",
    "    def display_reconstruction(self, epoch, originals, reconstructions):\n",
    "        n = 10  # Number of images to display\n",
    "        plt.figure(figsize=(20, 4))\n",
    "        for i in range(n):\n",
    "            # Display original\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            plt.imshow(originals[i].reshape(300, 300), cmap='gray')\n",
    "            plt.title(\"Original\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Display reconstruction\n",
    "            ax = plt.subplot(2, n, i + 1 + n)\n",
    "            plt.imshow(reconstructions[i].reshape(300, 300), cmap='gray')\n",
    "            plt.title(\"Reconstructed\")\n",
    "            plt.axis('off')\n",
    "        plt.suptitle(f'Epoch {epoch}')\n",
    "        plt.savefig(f'Results/MSE/Resnext2_{epoch}.png')\n",
    "        plt.close()\n",
    "\n",
    "# Define the model checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='Results/weights/Resnext_best_weights.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_weights_only=True,\n",
    "    save_freq=20,\n",
    ")\n",
    "\n",
    "# Model Training\n",
    "model.fit(x_train, x_train, epochs=1, shuffle=True, batch_size=1, validation_data=(x_val, x_val), callbacks=[CustomCallback(x_print), checkpoint_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envguilhem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
