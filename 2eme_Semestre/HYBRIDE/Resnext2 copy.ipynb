{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # type: ignore\n",
    "import os\n",
    "from tensorflow.keras.models import Model, load_model # type: ignore\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Reshape, Conv2DTranspose, Add, Resizing, LeakyReLU, UpSampling2D, Dropout, Concatenate, AveragePooling2D, GlobalMaxPooling2D, Lambda, ZeroPadding2D  # type: ignore\n",
    "from keras.initializers import glorot_uniform # type: ignore\n",
    "from tensorflow.keras.optimizers import SGD, Adam # type: ignore\n",
    "from tensorflow.keras.regularizers import l2 # type: ignore\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay # type: ignore\n",
    "from tensorflow.keras.losses import MeanSquaredError, CategoricalCrossentropy, MeanAbsoluteError # type: ignore\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "import keras_tuner as kt # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui genere des vecteurs aleatoires\n",
    "def generate_unique_vectors(num_vectors, vector_length, vectors):\n",
    "    vectors_list = []\n",
    "    while len(vectors_list) < num_vectors:\n",
    "        vector = tuple(np.random.randint(0, 2, vector_length))\n",
    "        if vector not in vectors:\n",
    "            vectors.add(vector)\n",
    "            vectors_list.append(vector)\n",
    "    return vectors_list, vectors\n",
    "\n",
    "# Fonction qui convertie le generateur en tableau numpy\n",
    "def generator_to_array(generator, class_vectors):\n",
    "    samples = []\n",
    "    vectors = []\n",
    "    data_filenames = generator.filenames\n",
    "    total_images = len(data_filenames)\n",
    "\n",
    "    for i in range(len(generator)):\n",
    "        batch = next(generator)\n",
    "        batch_size = len(batch[0])\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            index = i * generator.batch_size + j\n",
    "            if index >= total_images:\n",
    "                break  # Prevent going out of bounds\n",
    "\n",
    "            samples.append(batch[0][j])\n",
    "            class_name = data_filenames[index].split(os.path.sep)[0]\n",
    "            vectors.append(class_vectors[class_name])\n",
    "            \n",
    "    return np.array(samples), np.array(vectors), data_filenames\n",
    "\n",
    "# Fonction qui associe les images aux labels\n",
    "def preprocess(train_generator, val_generator, num_classes, vector_length, total_vectors, use_random_vectors):\n",
    "    class_indices = train_generator.class_indices\n",
    "    \n",
    "    if use_random_vectors:\n",
    "        unique_vectors, total_vectors = generate_unique_vectors(num_classes, vector_length, total_vectors)\n",
    "        class_vectors = {class_name: vector for class_name, vector in zip(class_indices, unique_vectors)}\n",
    "    else:\n",
    "        class_vectors = {class_name: i for i, class_name in enumerate(class_indices)}\n",
    "    \n",
    "    samples_train, vectors_train, _ = generator_to_array(train_generator, class_vectors)\n",
    "    samples_val, vectors_val, _ = generator_to_array(val_generator, class_vectors)\n",
    "    \n",
    "    if not use_random_vectors:\n",
    "        # Convert class indices to one-hot encoding\n",
    "        vectors_train = to_categorical(vectors_train, num_classes=num_classes)\n",
    "        vectors_val = to_categorical(vectors_val, num_classes=num_classes)\n",
    "    \n",
    "    return samples_train, vectors_train, samples_val, vectors_val, total_vectors\n",
    "\n",
    "# Fonction qui charge les donnees\n",
    "def load_data(datagen, target_size=(150, 150), batch_size=112, class_mode='input', shuffle=False, color_mode='grayscale', use_random_vectors=True, vector_length=56):\n",
    "    ethnies = {'caucasians': [], 'afro_americans': [], 'asians': []}\n",
    "    total_vectors = set()\n",
    "    #check = True\n",
    "    for ethnie in ethnies.keys():\n",
    "        trainset = datagen.flow_from_directory(f'../../Datasets/VGG/{ethnie}', target_size=target_size, batch_size=batch_size, class_mode=class_mode, shuffle=shuffle, color_mode=color_mode, subset='training')\n",
    "        testset  = datagen.flow_from_directory(f'../../Datasets/VGG/{ethnie}', target_size=target_size, batch_size=batch_size, class_mode=class_mode, shuffle=shuffle, color_mode=color_mode, subset='validation')\n",
    "        \n",
    "        # Number of classes for one-hot encoding\n",
    "        num_classes = len(trainset.class_indices)\n",
    "        \n",
    "        samples_train, vectors_train, samples_val, vectors_val, total_vectors = preprocess(trainset, testset, num_classes, vector_length, total_vectors, use_random_vectors)\n",
    "        \n",
    "        \"\"\" if trainset.n != samples_train.shape[0] or testset.n != samples_val.shape[0]: check = False \"\"\"\n",
    "        ethnies[ethnie] = [trainset, testset, samples_train, vectors_train, samples_val, vectors_val]\n",
    "    #print(check)\n",
    "    return ethnies\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.05, dtype='float16')\n",
    "\n",
    "ethnies = load_data(datagen, target_size=(300, 300), color_mode='grayscale', use_random_vectors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cau = ethnies['caucasians'][2][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cau.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(300,300,1)))\n",
    "model.add(MaxPooling2D((2,2), padding='same'))\n",
    "model.add(Conv2D(32, (3,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D((2,2), padding='same'))\n",
    "model.add(Conv2D(16, (3,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D((2,2), padding='same'))\n",
    "\n",
    "model.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(1, (3,3), activation='relu', padding='same'))\n",
    "\n",
    "model.add(Resizing(height=300, width=300, name='recon_image'))\n",
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(img_cau, img_cau, epochs=2000, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(img_cau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred[1].reshape(300,300,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # Number of images to display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):    \n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(pred[i].reshape(300, 300), cmap='gray')\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(inputs, cardinality):\n",
    "    inputs_channels = inputs.shape[3]\n",
    "    group_size = inputs_channels // cardinality    \n",
    "    groups = list()\n",
    "    for number in range(1, cardinality+1):\n",
    "        begin = int((number-1)*group_size)\n",
    "        end = int(number*group_size)\n",
    "        block = Lambda(lambda x:x[:,:,:,begin:end])(inputs)\n",
    "        groups.append(block)\n",
    "    return groups\n",
    "\n",
    "def transform(groups, filters, strides, stage, block, downsampling):\n",
    "    f1, f2 = filters    \n",
    "    conv_name = \"conv2d-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    bn_name = \"batchnorm-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    \n",
    "    transformed_tensor = list()\n",
    "    i = 1\n",
    "    \n",
    "    for inputs in groups:\n",
    "        # first conv of the transformation phase\n",
    "        x = Conv2D(filters=f1, kernel_size=(1,1), padding=\"valid\", \n",
    "                   kernel_initializer=glorot_uniform(seed=0))(inputs) #name=conv_name+'1a_split'+str(i), \n",
    "        if downsampling:\n",
    "            x = MaxPooling2D(2)(x)\n",
    "        x = BatchNormalization(axis=3)(x) #name=bn_name+'1a_split'+str(i)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        # second conv of the transformation phase\n",
    "        x = Conv2D(filters=f2, kernel_size=(3,3), strides=(1,1), padding=\"same\", \n",
    "                   kernel_initializer=glorot_uniform(seed=0))(x) #name=conv_name+'1b_split'+str(i), \n",
    "        x = BatchNormalization(axis=3)(x) #name=bn_name+'1b_split'+str(i)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        # Add x to transformed tensor list\n",
    "        transformed_tensor.append(x)\n",
    "        i+=1\n",
    "        \n",
    "    # Concatenate all tensor from each group\n",
    "    x = Concatenate()(transformed_tensor)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def transition(inputs, filters, stage, block):\n",
    "    x = Conv2D(filters=filters, kernel_size=(1,1), strides=(1,1), padding=\"valid\", \n",
    "                   kernel_initializer=glorot_uniform(seed=0))(inputs) #name='conv2d-trans'+str(stage)+''+block, \n",
    "    x = BatchNormalization(axis=3)(x) #name='batchnorm-trans'+str(stage)+''+block\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(inputs, filters, cardinality, stage, block, strides=(1,1)):    \n",
    "    identity = True\n",
    "\n",
    "    conv_name = \"conv2d-{stage}{block}-branch\".format(stage=str(stage),block=str(block))\n",
    "    bn_name = \"batchnorm-{stage}{block}-branch\".format(stage=str(stage),block=str(block))\n",
    "    \n",
    "    #save the input tensor value\n",
    "    x_shortcut = inputs\n",
    "    x = inputs\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    # divide input channels into groups. The number of groups is define by cardinality param\n",
    "    groups = split(inputs=x, cardinality=cardinality)\n",
    "    \n",
    "    # transform each group by doing a set of convolutions and concat the results\n",
    "    f1 = int(f1 / cardinality)\n",
    "    f2 = int(f2 / cardinality)\n",
    "    x = transform(groups=groups, filters=(f1, f2), strides=strides, stage=stage, block=block, downsampling=False)\n",
    "    # make a transition by doing 1x1 conv\n",
    "    x = transition(inputs=x, filters=f3, stage=stage, block=block)\n",
    "    # Last step of the identity block, shortcut concatenation\n",
    "    x = Add()([x,x_shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    print(x.shape)\n",
    "    return x\n",
    "\n",
    "def downsampling(inputs, filters, cardinality, strides, stage, block):    \n",
    "    # useful variables\n",
    "    conv_name = \"conv2d-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    bn_name = \"batchnorm-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    \n",
    "    # Retrieve filters for each layer\n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    # save the input tensor value\n",
    "    x_shortcut = inputs\n",
    "    x = inputs\n",
    "    \n",
    "    # divide input channels into groups. The number of groups is define by cardinality param\n",
    "    groups = split(inputs=x, cardinality=cardinality)\n",
    "    \n",
    "    # transform each group by doing a set of convolutions and concat the results\n",
    "    f1 = int(f1 / cardinality)\n",
    "    f2 = int(f2 / cardinality)\n",
    "    x = transform(groups=groups, filters=(f1, f2), strides=strides, stage=stage, block=block, downsampling=True)\n",
    "    print(x.shape, 'transfo downsampling')\n",
    "    # make a transition by doing 1x1 conv\n",
    "    x = transition(inputs=x, filters=f3, stage=stage, block=block)\n",
    "    print(x.shape, 'transi downsampling')\n",
    "    # Projection Shortcut to match dimensions \n",
    "    x_shortcut = Conv2D(filters=f3, kernel_size=(1,1), padding=\"valid\",\n",
    "               kernel_initializer=glorot_uniform(seed=0))(x_shortcut) #name='{base}2'.format(base=conv_name),\n",
    "    x_shortcut = MaxPooling2D(2)(x_shortcut)\n",
    "    x_shortcut = BatchNormalization(axis=3)(x_shortcut) #, name='{base}2'.format(base=bn_name)\n",
    "    #print(x.shape, x_shortcut.shape)\n",
    "    # Add x and x_shortcut\n",
    "    x = Add()([x,x_shortcut])\n",
    "    #print(x.shape)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_decoder(groups, filters, strides, stage, block):\n",
    "    conv_name = \"transpo_conv2d-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    bn_name = \"transpo_batchnorm-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    \n",
    "    transformed_tensor = []\n",
    "    f1, f2 = filters\n",
    "    i = 1\n",
    "    \n",
    "    for inputs in groups:\n",
    "        # first conv transpose of the transformation phase\n",
    "        x = Conv2DTranspose(filters=f1, kernel_size=(1,1), strides=(1,1), padding=\"same\", \n",
    "                            kernel_initializer=glorot_uniform(seed=0))(inputs) #name=conv_name+'2a_split'+str(i),\n",
    "        x = BatchNormalization(axis=3)(x) #name=bn_name+'2a_split'+str(i)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        # second conv transpose of the transformation phase\n",
    "        x = Conv2DTranspose(filters=f2, kernel_size=(3,3), strides=strides, padding=\"same\", \n",
    "                            kernel_initializer=glorot_uniform(seed=0))(x) #name=conv_name+'2b_split'+str(i), \n",
    "        x = BatchNormalization(axis=3)(x) #name=bn_name+'2b_split'+str(i)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        transformed_tensor.append(x)\n",
    "        i += 1\n",
    "        \n",
    "    x = Concatenate()(transformed_tensor)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def transition_decoder(inputs, filters, stage, block):\n",
    "    conv_name = \"transpo_conv2d-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    bn_name = \"transpo_batchnorm-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    \n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=(1,1), strides=(1,1), padding=\"valid\", \n",
    "                        kernel_initializer=glorot_uniform(seed=0))(inputs) #name=conv_name+'2',\n",
    "    x = BatchNormalization(axis=3)(x) #, name=bn_name+'2')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def identity_block_decoder(inputs, filters, cardinality, stage, block, strides=(1,1)):\n",
    "    conv_name = \"conv2d-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    bn_name = \"batchnorm-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    \n",
    "    # Sauvegarder la valeur du tenseur d'entrée\n",
    "    x_shortcut = inputs\n",
    "    x = inputs\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    # Diviser les canaux d'entrée en groupes. Le nombre de groupes est défini par le paramètre cardinalité\n",
    "    groups = split(inputs=x, cardinality=cardinality)\n",
    "    \n",
    "    # Transformer chaque groupe en faisant un ensemble de convolutions transposées et concaténer les résultats\n",
    "    f1 = int(f1 / cardinality)\n",
    "    f2 = int(f2 / cardinality)\n",
    "    x = transform_decoder(groups=groups, filters=(f1, f2), strides=strides, stage=stage, block=block)\n",
    "    \n",
    "    # Faire une transition en utilisant 1x1 conv transposée\n",
    "    x = transition_decoder(inputs=x, filters=f3, stage=stage, block=block)\n",
    "    \n",
    "    # Dernière étape du bloc d'identité, concaténation du raccourci\n",
    "    x = Add()([x, x_shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def upsampling(inputs, filters, cardinality, strides, stage, block):\n",
    "    # Variables utiles\n",
    "    conv_name = \"transpo_conv2d-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    bn_name = \"transpo_batchnorm-{stage}{block}-branch\".format(stage=str(stage), block=str(block))\n",
    "    \n",
    "    # Récupérer les filtres pour chaque couche\n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    # Sauvegarder la valeur du tenseur d'entrée\n",
    "    x_shortcut = inputs\n",
    "    x = inputs\n",
    "    \n",
    "    # Diviser les canaux d'entrée en groupes. Le nombre de groupes est défini par le paramètre cardinalité\n",
    "    groups = split(inputs=x, cardinality=cardinality)\n",
    "    \n",
    "    # Transformer chaque groupe en faisant un ensemble de convolutions transposées et concaténer les résultats\n",
    "    f1 = int(f1 / cardinality)\n",
    "    f2 = int(f2 / cardinality)\n",
    "    x = transform_decoder(groups=groups, filters=(f1, f2), strides=strides, stage=stage, block=block)\n",
    "    print(x.shape, 'transfo')\n",
    "    # Faire une transition en utilisant 1x1 conv transposée\n",
    "    x = transition_decoder(inputs=x, filters=f3, stage=stage, block=block)\n",
    "    print(x.shape, 'transi')\n",
    "    # Projection du raccourci pour correspondre aux dimensions\n",
    "    x_shortcut = Conv2DTranspose(filters=f3, kernel_size=(1,1), strides=strides, padding=\"valid\", \n",
    "                                 kernel_initializer=glorot_uniform(seed=0))(x_shortcut) #name='{base}2'.format(base=conv_name), \n",
    "    x_shortcut = BatchNormalization(axis=3)(x_shortcut) #, name='{base}2'.format(base=bn_name))(x_shortcut)\n",
    "    \n",
    "    # Ajouter x et x_shortcut\n",
    "    x = Add()([x, x_shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNeXt50_AutoEncoder(input_shape, input_latent):\n",
    "    # Transform input to a tensor of shape input_shape\n",
    "    x_input = Input(input_shape)\n",
    "    \n",
    "    # Add zero padding\n",
    "    x = ZeroPadding2D((3, 3))(x_input)\n",
    "    \n",
    "    # Initial Stage (Encoder)\n",
    "    x = Conv2D(filters=128, kernel_size=(5, 5), kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis=3, name='batchnorm_1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    filters = [256, 256, 512, 512, 1024]\n",
    "\n",
    "    for filter in filters:\n",
    "        x = downsampling(inputs=x, filters=(filter, filter, filter*2), cardinality=128, strides=(2, 2), stage=1, block=\"a\")\n",
    "        print(x.shape, \" en dehors de la f down\")\n",
    "        \"\"\" \n",
    "        x = identity_block(inputs=x, filters=(filter, filter, filter*2), cardinality=32, stage=1, block=\"b\")\n",
    "        x = identity_block(inputs=x, filters=(filter, filter, filter*2), cardinality=32, stage=1, block=\"c\") \"\"\"\n",
    "\n",
    "    x = Conv2D(filters=1024, kernel_size=(1, 1), kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(filters=2048, kernel_size=(1, 1), kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    print(x.shape, 'dernière reduc')\n",
    "    # Stage 2 (Encoder)\n",
    "    \n",
    "    # Bottleneck\n",
    "    x = Conv2D(input_latent, 2, padding='same', use_bias=False)(x)\n",
    "    x = Flatten()(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    # Latent space\n",
    "    latent_space_layer = Dense(input_latent, activation='relu', use_bias=False)(x)\n",
    "    latent_space_layer_norm = BatchNormalization(name='latent_space_layer_norm')(latent_space_layer)\n",
    "\n",
    "    # Reconstruction\n",
    "    reshape_layer = Reshape(target_shape=(1, 1, input_latent))(latent_space_layer_norm)\n",
    "    x_recon = Conv2DTranspose(input_latent, 3, strides=1, padding='same', use_bias=False)(reshape_layer)\n",
    "    \n",
    "    print(x_recon.shape)\n",
    "    # Stage 5 (Decoder)\n",
    "\n",
    "    x_recon = Conv2DTranspose(filters=2048, kernel_size=(3,3), strides=1)(x_recon)\n",
    "    x_recon = BatchNormalization(axis=3)(x_recon)\n",
    "    x_recon = Activation('relu')(x_recon)\n",
    "    x_recon = Conv2DTranspose(filters=1024, kernel_size=(3, 3), strides=1)(x_recon)\n",
    "    x_recon = BatchNormalization(axis=3)(x_recon)\n",
    "    x_recon = Activation('relu')(x_recon)\n",
    "\n",
    "    for filter in reversed(filters):\n",
    "        x_recon = upsampling(inputs=x_recon, filters=(filter*2, filter*2, filter), cardinality=128, strides=(2, 2), stage=5, block=\"a\")\n",
    "        print(x_recon.shape)\n",
    "        \"\"\" \n",
    "        x_recon = identity_block_decoder(inputs=x_recon, filters=(filter*2, filter*2, filter), cardinality=32, stage=5, block=\"b\")\n",
    "        x_recon = identity_block_decoder(inputs=x_recon, filters=(filter*2, filter*2, filter), cardinality=32, stage=5, block=\"c\") \"\"\"\n",
    "        \n",
    "    x_recon = upsampling(inputs=x_recon, filters=(filter*2, filter*2, filter), cardinality=128, strides=(2, 2), stage=5, block=\"a\")\n",
    "    print(x_recon.shape)\n",
    "    # Final Convolution to reconstruct the image    \n",
    "    x_recon = Conv2DTranspose(1, (1, 1), padding='same', activation='sigmoid')(x_recon)\n",
    "    x_recon = tf.keras.layers.Resizing(height=input_shape[0], width=input_shape[1], name='recon_image')(x_recon)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=x_input, outputs=x_recon, name=\"resnext50_autoencoder\")\n",
    "    \n",
    "    lr_schedule = ExponentialDecay(initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9, staircase=True)\n",
    "    optimizer = SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "    model.compile(optimizer=optimizer, loss=MeanSquaredError())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model creation\n",
    "model = ResNeXt50_AutoEncoder(input_shape=(300, 300, 1), input_latent=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "ethnie = 'caucasians'\n",
    "x_train = ethnies[ethnie][2]\n",
    "x_val = ethnies[ethnie][4]\n",
    "x_print = x_val.copy()\n",
    "np.random.shuffle(x_print)\n",
    "x_print = x_print[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Callback Definition\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_data, display_loss_interval=10, display_recon_interval=20):\n",
    "        super().__init__()\n",
    "        self.test_data = test_data\n",
    "        self.display_loss_interval = display_loss_interval\n",
    "        self.display_recon_interval = display_recon_interval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.display_recon_interval == 0:\n",
    "            reconstructions = self.model.predict(self.test_data, verbose=0)\n",
    "            self.display_reconstruction(epoch+1, self.test_data, reconstructions)\n",
    "        if epoch % self.display_loss_interval == 0:\n",
    "            print(f\"Epoch {epoch+1}, Loss: {logs['loss']:.4g}\")\n",
    "\n",
    "    def display_reconstruction(self, epoch, originals, reconstructions):\n",
    "        n = 10  # Number of images to display\n",
    "        plt.figure(figsize=(20, 4))\n",
    "        for i in range(n):\n",
    "            # Display original\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            plt.imshow(originals[i].reshape(300, 300), cmap='gray')\n",
    "            plt.title(\"Original\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Display reconstruction\n",
    "            ax = plt.subplot(2, n, i + 1 + n)\n",
    "            plt.imshow(reconstructions[i].reshape(300, 300), cmap='gray')\n",
    "            plt.title(\"Reconstructed\")\n",
    "            plt.axis('off')\n",
    "        plt.suptitle(f'Epoch {epoch}')\n",
    "        plt.savefig(f'Results/MSE/Resnext2_{epoch}.png')\n",
    "        plt.close()\n",
    "\n",
    "# Define the model checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='Results/weights/Resnext_best_weights.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_weights_only=True,\n",
    "    save_freq=20,\n",
    ")\n",
    "\n",
    "# Model Training\n",
    "model.fit(x_train, x_train, epochs=1, shuffle=True, batch_size=1, validation_data=(x_val, x_val), callbacks=[CustomCallback(x_print), checkpoint_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envguilhem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
