{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60fff39f-e0f8-47d9-b7ae-8a3d3e8dafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import tensorflow as tf # type: ignore\n",
    "import os\n",
    "from tensorflow.keras.models import Model # type: ignore\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Reshape, Conv2DTranspose, Add, LeakyReLU, UpSampling2D, Dropout # type: ignore\n",
    "from tensorflow.keras.optimizers import SGD, Adam # type: ignore\n",
    "from tensorflow.keras.regularizers import l2 # type: ignore\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay # type: ignore\n",
    "from tensorflow.keras.losses import MeanSquaredError, CategoricalCrossentropy # type: ignore\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError, CategoricalAccuracy # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "import keras_tuner as kt # type: ignore\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "768fcc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4109 images belonging to 21 classes.\n",
      "Found 75 images belonging to 21 classes.\n",
      "Found 4363 images belonging to 22 classes.\n",
      "Found 80 images belonging to 22 classes.\n",
      "Found 4293 images belonging to 21 classes.\n",
      "Found 75 images belonging to 21 classes.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Fonction qui genere des vecteurs aleatoires\n",
    "def generate_unique_vectors(num_vectors, vector_length, vectors):\n",
    "    vectors_list = []\n",
    "    while len(vectors_list) < num_vectors:\n",
    "        vector = tuple(np.random.randint(0, 2, vector_length))\n",
    "        if vector not in vectors:\n",
    "            vectors.add(vector)\n",
    "            vectors_list.append(vector)\n",
    "    return vectors_list, vectors\n",
    "\n",
    "# Fonction qui convertie le generateur en tableau numpy\n",
    "def generator_to_array(generator, class_vectors):\n",
    "    samples = []\n",
    "    vectors = []\n",
    "    data_filenames = generator.filenames\n",
    "    total_images = len(data_filenames)\n",
    "\n",
    "    for i in range(len(generator)):\n",
    "        batch = generator.next()\n",
    "        batch_size = len(batch[0])\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            index = i * generator.batch_size + j\n",
    "            if index >= total_images:\n",
    "                break  # Prevent going out of bounds\n",
    "\n",
    "            samples.append(batch[0][j])\n",
    "            class_name = data_filenames[index].split(os.path.sep)[0]\n",
    "            vectors.append(class_vectors[class_name])\n",
    "            \n",
    "    return np.array(samples), np.array(vectors), data_filenames\n",
    "\n",
    "# Fonction qui associe les images aux labels\n",
    "def preprocess(train_generator, val_generator, num_classes, vector_length, total_vectors, use_random_vectors):\n",
    "    class_indices = train_generator.class_indices\n",
    "    \n",
    "    if use_random_vectors:\n",
    "        unique_vectors, total_vectors = generate_unique_vectors(num_classes, vector_length, total_vectors)\n",
    "        class_vectors = {class_name: vector for class_name, vector in zip(class_indices, unique_vectors)}\n",
    "    else:\n",
    "        class_vectors = {class_name: i for i, class_name in enumerate(class_indices)}\n",
    "    \n",
    "    samples_train, vectors_train, _ = generator_to_array(train_generator, class_vectors)\n",
    "    samples_val, vectors_val, _ = generator_to_array(val_generator, class_vectors)\n",
    "    \n",
    "    if not use_random_vectors:\n",
    "        # Convert class indices to one-hot encoding\n",
    "        vectors_train = to_categorical(vectors_train, num_classes=num_classes)\n",
    "        vectors_val = to_categorical(vectors_val, num_classes=num_classes)\n",
    "    \n",
    "    return samples_train, vectors_train, samples_val, vectors_val, total_vectors\n",
    "\n",
    "# Fonction qui charge les donnees\n",
    "def load_data(datagen, target_size=(150, 150), batch_size=112, class_mode='input', shuffle=False, color_mode='grayscale', use_random_vectors=True, vector_length=56):\n",
    "    ethnies = {'caucasians': [], 'afro_americans': [], 'asians': []}\n",
    "    total_vectors = set()\n",
    "    check = True\n",
    "    for ethnie in ethnies.keys():\n",
    "        trainset = datagen.flow_from_directory(f'../../Datasets/VGG/{ethnie}', target_size=target_size, batch_size=batch_size, class_mode=class_mode, shuffle=shuffle, color_mode=color_mode, subset='training')\n",
    "        testset  = datagen.flow_from_directory(f'../../Datasets/VGG/{ethnie}', target_size=target_size, batch_size=batch_size, class_mode=class_mode, shuffle=shuffle, color_mode=color_mode, subset='validation')\n",
    "        \n",
    "        # Number of classes for one-hot encoding\n",
    "        num_classes = len(trainset.class_indices)\n",
    "        \n",
    "        samples_train, vectors_train, samples_val, vectors_val, total_vectors = preprocess(trainset, testset, num_classes, vector_length, total_vectors, use_random_vectors)\n",
    "        \n",
    "        if trainset.n != samples_train.shape[0] or testset.n != samples_val.shape[0]:\n",
    "            check = False\n",
    "        ethnies[ethnie] = [trainset, testset, samples_train, vectors_train, samples_val, vectors_val]\n",
    "    print(check)\n",
    "    return ethnies\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.02, dtype='float16')\n",
    "\n",
    "# Exemple vecteurs aleatoires\n",
    "#ethnies_random = load_data(datagen, use_random_vectors=True)\n",
    "\n",
    "# Exemple vecteur one-hot\n",
    "#ethnies_onehot = load_data(datagen, use_random_vectors=False)\n",
    "ethnies = load_data(datagen, target_size=(256, 256), use_random_vectors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1868e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définition des blocs résiudels\n",
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, kernel_size, strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = Conv2D(filters, kernel_size, strides=1, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    if stride != 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, 1, strides=stride, padding='same', use_bias=False)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    x = Add()([x, shortcut])\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "def residual_block_recon(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv2DTranspose(filters, kernel_size, strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = Conv2DTranspose(filters, kernel_size, strides=1, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    shortcut = Conv2DTranspose(filters, 1, strides=stride, padding='same', use_bias=False)(shortcut)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    x = Add()([x, shortcut])\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b4a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hybride(shape=(256, 256, 1), input_latent=512, len_vecteur=56):\n",
    "    input_img = Input(shape=shape, name='input_image')\n",
    "    #print(input_img.shape)\n",
    "    x = Conv2D(16, 5, strides=2, padding='same', use_bias=False)(input_img)\n",
    "    #print(x.shape)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(2, strides=2, padding='same')(x)\n",
    "    #print(x.shape, \"max pool\")\n",
    "    #encoder\n",
    "    x = residual_block(x, 32, 3, 2)\n",
    "    #print(x.shape)\n",
    "    x = residual_block(x, 64, 3, 2)\n",
    "    #print(x.shape)\n",
    "    x = residual_block(x, 128, 3, 2)\n",
    "    #print(x.shape)\n",
    "    x = residual_block(x, 256, 3, 2)\n",
    "    #print(x.shape)\n",
    "    x = residual_block(x, 512, 3, 2)\n",
    "    #print(x.shape, \"bloc 512\")\n",
    "    x = Conv2D(input_latent, 3, strides=2, padding='same', use_bias=False)(x)\n",
    "    #print(x.shape, \"espace latent\")\n",
    "\n",
    "    #espace latent\n",
    "    latent_space_layer = Dense(input_latent, activation='relu', use_bias=False)(x)\n",
    "    latent_space_layer_norm = BatchNormalization(name='latent_space_layer_norm')(latent_space_layer)\n",
    "\n",
    "    #decoder\n",
    "    reshape_layer = Reshape(target_shape=(1, 1, input_latent))(latent_space_layer_norm)\n",
    "    #print(reshape_layer.shape, 'reshape_layer')\n",
    "    x_recon = residual_block_recon(reshape_layer, input_latent, 3, 2)\n",
    "    #print(x_recon.shape, \"bloc 512\")\n",
    "    x_recon = residual_block_recon(x_recon, 256, 3, 2)\n",
    "    #print(x_recon.shape)\n",
    "    x_recon = residual_block_recon(x_recon, 128, 3, 2)\n",
    "    #print(x_recon.shape)\n",
    "    x_recon = residual_block_recon(x_recon, 64, 3, 2)\n",
    "    #print(x_recon.shape)\n",
    "    x_recon = residual_block_recon(x_recon, 32, 3, 2)\n",
    "    #print(x_recon.shape)\n",
    "    x_recon = Conv2DTranspose(16, 2, strides=2, padding='same', use_bias=False)(x_recon)\n",
    "    #print(x_recon.shape, \"unverse max pool\")\n",
    "    x_recon = Conv2DTranspose(16, 5, strides=2, padding='same', use_bias=False)(x_recon)\n",
    "    #print(x_recon.shape)\n",
    "    x_recon = Conv2DTranspose(1, 1, activation='sigmoid', padding='same', use_bias=False)(x_recon)\n",
    "    #print(x_recon.shape, 'recon_image')\n",
    "    x_recon = tf.keras.layers.Resizing(height=256, width=256, name='recon_image')(x_recon)\n",
    "\n",
    "    #classification\n",
    "    x_class = Dense(128, activation='relu')(latent_space_layer_norm)\n",
    "    x_class = Dense(len_vecteur, activation='softmax', name='classif')(x_class)\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=[x_recon, x_class])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=ExponentialDecay(initial_learning_rate=0.001, decay_steps=42237,decay_rate=0.5,staircase=False))\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss={'recon_image': MeanSquaredError(), 'classif': MeanSquaredError()},\n",
    "                  metrics={'recon_image': MeanAbsoluteError(), 'classif': 'accuracy'})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c77bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybride = create_hybride()\n",
    "model_hybride.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857cc49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "def residual_block(x, filters, kernel_size, stride):\n",
    "    shortcut = Conv2D(filters, 1, strides=stride, padding='same', use_bias=False)(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, strides=1, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def residual_block_recon(x, filters, kernel_size, stride):\n",
    "    shortcut = Conv2DTranspose(filters, 1, strides=stride, padding='same', use_bias=False)(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    x = Conv2DTranspose(filters, kernel_size, strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2DTranspose(filters, kernel_size, strides=1, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_autoencoder(shape=(256, 256, 1), input_latent=512):\n",
    "    input_img = Input(shape=shape, name='input_image')\n",
    "    print(input_img.shape)\n",
    "\n",
    "    # Encoder\n",
    "    x = Conv2D(16, 5, strides=2, padding='same', use_bias=False)(input_img)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    print(x.shape, \"1ere conv\")\n",
    "    x = MaxPooling2D(2, strides=2, padding='same')(x)\n",
    "    print(x.shape, \"max pool\")\n",
    "    x = residual_block(x, 32, 3, 2)\n",
    "    print(x.shape)\n",
    "    x = residual_block(x, 64, 3, 2)\n",
    "    print(x.shape)\n",
    "    x = residual_block(x, 128, 3, 2)\n",
    "    print(x.shape)\n",
    "    x = residual_block(x, 256, 3, 2)\n",
    "    print(x.shape)\n",
    "    x = residual_block(x, 512, 3, 2)\n",
    "    print(x.shape)\n",
    "    x = residual_block(x, 1024, 3, 2)\n",
    "    print(x.shape, \"bloc 1024\")\n",
    "    x = Conv2D(input_latent, 3, strides=1, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(LeakyReLU(alpha=0.1))(x)\n",
    "    print(x.shape, \"espace latent\")\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Latent space\n",
    "    latent_space_layer = Dense(input_latent, activation='relu', use_bias=False)(x)\n",
    "    latent_space_layer_norm = BatchNormalization(name='latent_space_layer_norm')(latent_space_layer)\n",
    "    \n",
    "    # Decoder\n",
    "    reshape_layer = Reshape(target_shape=(1, 1, input_latent))(latent_space_layer_norm)\n",
    "    print(reshape_layer.shape, 'reshape_layer')\n",
    "    x_recon = Conv2DTranspose(input_latent, 3, strides=1, padding='same', use_bias=False)(reshape_layer)\n",
    "    x_recon = BatchNormalization()(x_recon)\n",
    "    x_recon = Activation(LeakyReLU(alpha=0.1))(x_recon)\n",
    "    print(x_recon.shape)\n",
    "    x_recon = residual_block_recon(x_recon, 1024, 3, 2)\n",
    "    print(x_recon.shape, \"bloc 1024\")\n",
    "    x_recon = residual_block_recon(x_recon, 512, 3, 2)\n",
    "    print(x_recon.shape, \"bloc 512\")\n",
    "    x_recon = residual_block_recon(x_recon, 256, 3, 2)\n",
    "    print(x_recon.shape)\n",
    "    x_recon = residual_block_recon(x_recon, 128, 3, 2)\n",
    "    print(x_recon.shape)\n",
    "    x_recon = residual_block_recon(x_recon, 64, 3, 2)\n",
    "    print(x_recon.shape)\n",
    "    x_recon = residual_block_recon(x_recon, 32, 3, 2)\n",
    "    print(x_recon.shape)\n",
    "    x_recon = Conv2DTranspose(16, 3, strides=2, padding='same', use_bias=False)(x_recon)\n",
    "    x_recon = BatchNormalization()(x_recon)\n",
    "    x_recon = Activation('relu')(x_recon)\n",
    "    print(x_recon.shape, \"unverse max pool\")\n",
    "    x_recon = Conv2DTranspose(16, 5, strides=2, padding='same', use_bias=False)(x_recon)\n",
    "    x_recon = BatchNormalization()(x_recon)\n",
    "    x_recon = Activation('relu')(x_recon)\n",
    "    print(x_recon.shape)\n",
    "    x_recon = Conv2DTranspose(1, 1, activation='sigmoid', padding='same', use_bias=False)(x_recon)\n",
    "    print(x_recon.shape, 'recon_image')\n",
    "    x_recon = tf.keras.layers.Resizing(height=256, width=256, name='recon_image')(x_recon)\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=x_recon)\n",
    "\n",
    "    lr_schedule = ExponentialDecay(initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9, staircase=True)\n",
    "\n",
    "    optimizer = SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "    model.compile(optimizer=optimizer, loss=MeanAbsoluteError())\n",
    "    return model\n",
    "\n",
    "model = create_autoencoder()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebcf2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = create_autoencoder()\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6c3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir un callback personnalisé pour afficher la reconstruction toutes les 10 époques\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, test_data, display_loss_interval=10, display_recon_interval=50):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.test_data = test_data\n",
    "        self.display_loss_interval = display_loss_interval\n",
    "        self.display_recon_interval = display_recon_interval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % self.display_recon_interval == 0:\n",
    "            reconstructions = self.model.predict(self.test_data)\n",
    "            self.display_reconstruction(epoch, self.test_data, reconstructions)\n",
    "        if epoch % self.display_loss_interval == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {logs['loss']:.6g}\")\n",
    "\n",
    "\n",
    "    def display_reconstruction(self, epoch, originals, reconstructions):\n",
    "        n = 10  # Number of images to display\n",
    "        plt.figure(figsize=(20, 4))\n",
    "        for i in range(n):\n",
    "            # Display original\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            plt.imshow(originals[i].reshape(256, 256), cmap='gray')\n",
    "            plt.title(\"Original\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Display reconstruction\n",
    "            ax = plt.subplot(2, n, i + 1 + n)\n",
    "            plt.imshow(reconstructions[i].reshape(256, 256), cmap='gray')\n",
    "            plt.title(\"Reconstructed\")\n",
    "            plt.axis('off')\n",
    "        plt.suptitle(f'Epoch {epoch}')\n",
    "        plt.show()\n",
    "\n",
    "ethnie = 'afro_americans'\n",
    "x_train = ethnies[ethnie][2] ; y_train = ethnies[ethnie][3]\n",
    "x_val   = ethnies[ethnie][4] ; y_val   = ethnies[ethnie][5]\n",
    "x_print = x_val.copy(); np.random.shuffle(x_print); x_print = x_print[:10]\n",
    "\n",
    "# Entraîner le modèle avec le callback personnalisé\n",
    "model.fit(x_train, x_train, epochs=5000, batch_size=32, callbacks=[CustomCallback(model, x_print)], verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb4a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_latent = pca(dico_latent, \"afro_americans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19afc54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder(shape=(256, 256, 1), input_latent=512):\n",
    "    input_img = Input(shape=shape, name='input_image')\n",
    "\n",
    "    # Encoder\n",
    "    x = Conv2D(16, 5, strides=2, padding='same', use_bias=False)(input_img)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(2, strides=2, padding='same')(x)\n",
    "    x = residual_block(x, 32, 3, 2)\n",
    "    x = residual_block(x, 64, 3, 2)\n",
    "    x = residual_block(x, 128, 3, 2)\n",
    "    x = residual_block(x, 256, 3, 2)\n",
    "    x = residual_block(x, 512, 3, 2)\n",
    "    x = Conv2D(input_latent, 3, strides=2, padding='same', use_bias=False)(x)\n",
    "\n",
    "    # Latent space\n",
    "    latent_space_layer = Dense(input_latent, activation='relu', use_bias=False)(x)\n",
    "    latent_space_layer_norm = BatchNormalization(name='latent_space_layer_norm')(latent_space_layer)\n",
    "\n",
    "    # Decoder\n",
    "    reshape_layer = Reshape(target_shape=(1, 1, input_latent))(latent_space_layer_norm)\n",
    "    x_recon = residual_block_recon(reshape_layer, input_latent, 3, 2)\n",
    "    x_recon = residual_block_recon(x_recon, 256, 3, 2)\n",
    "    x_recon = residual_block_recon(x_recon, 128, 3, 2)\n",
    "    x_recon = residual_block_recon(x_recon, 64, 3, 2)\n",
    "    x_recon = residual_block_recon(x_recon, 32, 3, 2)\n",
    "    x_recon = Conv2DTranspose(16, 2, strides=2, padding='same', use_bias=False)(x_recon)\n",
    "    x_recon = BatchNormalization()(x_recon)\n",
    "    x_recon = Activation('relu')(x_recon)\n",
    "    x_recon = Conv2DTranspose(16, 5, strides=2, padding='same', use_bias=False)(x_recon)\n",
    "    x_recon = BatchNormalization()(x_recon)\n",
    "    x_recon = Activation('relu')(x_recon)\n",
    "    x_recon = Conv2DTranspose(1, 1, activation='sigmoid', padding='same', use_bias=False)(x_recon)\n",
    "    x_recon = tf.keras.layers.Resizing(height=256, width=256, name='recon_image')(x_recon)\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=x_recon)\n",
    "\n",
    "    lr_schedule = ExponentialDecay(initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9, staircase=True)\n",
    "    optimizer = SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "    model.compile(optimizer=optimizer, loss=MeanAbsoluteError())\n",
    "    return model\n",
    "\n",
    "ethnie = 'afro_americans'\n",
    "x_train = ethnies[ethnie][2] ; y_train = ethnies[ethnie][3]\n",
    "x_val   = ethnies[ethnie][4] ; y_val   = ethnies[ethnie][5]\n",
    "\n",
    "# Check for proper data shape\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "\n",
    "# Create and compile model\n",
    "model_autoencoder = create_autoencoder()\n",
    "\n",
    "# Train the model\n",
    "history = model_autoencoder.fit(x_train, x_train, batch_size=32, epochs=3000,\n",
    "                                validation_data=(x_val, x_val), shuffle=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoencoder = create_autoencoder()\n",
    "model_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnie = 'afro_americans'\n",
    "x_train = ethnies[ethnie][2] ; y_train = ethnies[ethnie][3]\n",
    "x_val   = ethnies[ethnie][4] ; y_val   = ethnies[ethnie][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58682c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "history = model_autoencoder.fit(x_train, x_train, batch_size=32, epochs=200,\n",
    "                    validation_data=(x_val, y_val), shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff236b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(shape=(256, 256, 1), input_latent=512, len_vecteur=56):\n",
    "    nbr_filters = [32, 64, 128, 256, 512, 1024, 2048]\n",
    "    input_img = Input(shape=shape, name='input_image')\n",
    "    x = Conv2D(16, 3, strides=2, padding='same', use_bias=False)(input_img)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    #encoder\n",
    "    for filtres in nbr_filters:\n",
    "        x = residual_block(x, filtres, 3, 2)\n",
    "        print(x.shape)\n",
    "    x = residual_block(x, input_latent, 3, 1)\n",
    "    print(x.shape)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Espace latent\n",
    "    latent_space_layer = Dense(input_latent, activation='relu', use_bias=False)(x)\n",
    "    latent_space_layer_norm = BatchNormalization(name='latent_space_layer_norm')(latent_space_layer)\n",
    "\n",
    "    # Classification\n",
    "    x_class = Dense(50, activation='relu', kernel_regularizer=l2(0.01))(latent_space_layer_norm)\n",
    "    x_class = BatchNormalization()(x_class)\n",
    "    x_class = Dense(25, activation='relu', kernel_regularizer=l2(0.01))(x_class)\n",
    "    x_class = BatchNormalization()(x_class)\n",
    "    x_class = Dense(len_vecteur, activation='softmax', name='classif')(x_class)\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=x_class)\n",
    "    \n",
    "    lr_schedule = ExponentialDecay(initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9, staircase=True)\n",
    "\n",
    "    optimizer = SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "    model.compile(optimizer=optimizer, loss=CategoricalCrossentropy(), metrics=CategoricalAccuracy())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6ce3496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 32)\n",
      "(None, 32, 32, 64)\n",
      "(None, 16, 16, 128)\n",
      "(None, 8, 8, 256)\n",
      "(None, 4, 4, 512)\n",
      "(None, 2, 2, 1024)\n",
      "(None, 1, 1, 2048)\n",
      "(None, 1, 1, 512)\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, 128, 128, 16  144         ['input_image[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_150 (Batch  (None, 128, 128, 16  64         ['conv2d_138[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 128, 128, 16  0           ['batch_normalization_150[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, 64, 64, 32)   4608        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_151 (Batch  (None, 64, 64, 32)  128         ['conv2d_139[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_88 (LeakyReLU)     (None, 64, 64, 32)   0           ['batch_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, 64, 64, 32)   9216        ['leaky_re_lu_88[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 64, 64, 32)   512         ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_152 (Batch  (None, 64, 64, 32)  128         ['conv2d_140[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_153 (Batch  (None, 64, 64, 32)  128         ['conv2d_141[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 64, 64, 32)   0           ['batch_normalization_152[0][0]',\n",
      "                                                                  'batch_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " leaky_re_lu_89 (LeakyReLU)     (None, 64, 64, 32)   0           ['add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, 32, 32, 64)   18432       ['leaky_re_lu_89[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_154 (Batch  (None, 32, 32, 64)  256         ['conv2d_142[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_90 (LeakyReLU)     (None, 32, 32, 64)   0           ['batch_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 32, 32, 64)   36864       ['leaky_re_lu_90[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, 32, 32, 64)   2048        ['leaky_re_lu_89[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_155 (Batch  (None, 32, 32, 64)  256         ['conv2d_143[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_156 (Batch  (None, 32, 32, 64)  256         ['conv2d_144[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 32, 32, 64)   0           ['batch_normalization_155[0][0]',\n",
      "                                                                  'batch_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " leaky_re_lu_91 (LeakyReLU)     (None, 32, 32, 64)   0           ['add_45[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 16, 16, 128)  73728       ['leaky_re_lu_91[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_157 (Batch  (None, 16, 16, 128)  512        ['conv2d_145[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_92 (LeakyReLU)     (None, 16, 16, 128)  0           ['batch_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, 16, 16, 128)  147456      ['leaky_re_lu_92[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, 16, 16, 128)  8192        ['leaky_re_lu_91[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_158 (Batch  (None, 16, 16, 128)  512        ['conv2d_146[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_159 (Batch  (None, 16, 16, 128)  512        ['conv2d_147[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 16, 16, 128)  0           ['batch_normalization_158[0][0]',\n",
      "                                                                  'batch_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " leaky_re_lu_93 (LeakyReLU)     (None, 16, 16, 128)  0           ['add_46[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, 8, 8, 256)    294912      ['leaky_re_lu_93[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_160 (Batch  (None, 8, 8, 256)   1024        ['conv2d_148[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_94 (LeakyReLU)     (None, 8, 8, 256)    0           ['batch_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, 8, 8, 256)    589824      ['leaky_re_lu_94[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)            (None, 8, 8, 256)    32768       ['leaky_re_lu_93[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 8, 8, 256)   1024        ['conv2d_149[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 8, 8, 256)   1024        ['conv2d_150[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 8, 8, 256)    0           ['batch_normalization_161[0][0]',\n",
      "                                                                  'batch_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " leaky_re_lu_95 (LeakyReLU)     (None, 8, 8, 256)    0           ['add_47[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)            (None, 4, 4, 512)    1179648     ['leaky_re_lu_95[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_163 (Batch  (None, 4, 4, 512)   2048        ['conv2d_151[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_96 (LeakyReLU)     (None, 4, 4, 512)    0           ['batch_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)            (None, 4, 4, 512)    2359296     ['leaky_re_lu_96[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)            (None, 4, 4, 512)    131072      ['leaky_re_lu_95[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_164 (Batch  (None, 4, 4, 512)   2048        ['conv2d_152[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_165 (Batch  (None, 4, 4, 512)   2048        ['conv2d_153[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_48 (Add)                   (None, 4, 4, 512)    0           ['batch_normalization_164[0][0]',\n",
      "                                                                  'batch_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " leaky_re_lu_97 (LeakyReLU)     (None, 4, 4, 512)    0           ['add_48[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)            (None, 2, 2, 1024)   4718592     ['leaky_re_lu_97[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_166 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_154[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_98 (LeakyReLU)     (None, 2, 2, 1024)   0           ['batch_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)            (None, 2, 2, 1024)   9437184     ['leaky_re_lu_98[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)            (None, 2, 2, 1024)   524288      ['leaky_re_lu_97[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_167 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_155[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_168 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_156[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_49 (Add)                   (None, 2, 2, 1024)   0           ['batch_normalization_167[0][0]',\n",
      "                                                                  'batch_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " leaky_re_lu_99 (LeakyReLU)     (None, 2, 2, 1024)   0           ['add_49[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)            (None, 1, 1, 2048)   18874368    ['leaky_re_lu_99[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_169 (Batch  (None, 1, 1, 2048)  8192        ['conv2d_157[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_100 (LeakyReLU)    (None, 1, 1, 2048)   0           ['batch_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)            (None, 1, 1, 2048)   37748736    ['leaky_re_lu_100[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)            (None, 1, 1, 2048)   2097152     ['leaky_re_lu_99[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_170 (Batch  (None, 1, 1, 2048)  8192        ['conv2d_158[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_171 (Batch  (None, 1, 1, 2048)  8192        ['conv2d_159[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_50 (Add)                   (None, 1, 1, 2048)   0           ['batch_normalization_170[0][0]',\n",
      "                                                                  'batch_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " leaky_re_lu_101 (LeakyReLU)    (None, 1, 1, 2048)   0           ['add_50[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)            (None, 1, 1, 512)    9437184     ['leaky_re_lu_101[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_172 (Batch  (None, 1, 1, 512)   2048        ['conv2d_160[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_102 (LeakyReLU)    (None, 1, 1, 512)    0           ['batch_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)            (None, 1, 1, 512)    2359296     ['leaky_re_lu_102[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)            (None, 1, 1, 512)    1048576     ['leaky_re_lu_101[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_173 (Batch  (None, 1, 1, 512)   2048        ['conv2d_161[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_174 (Batch  (None, 1, 1, 512)   2048        ['conv2d_162[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_51 (Add)                   (None, 1, 1, 512)    0           ['batch_normalization_173[0][0]',\n",
      "                                                                  'batch_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " leaky_re_lu_103 (LeakyReLU)    (None, 1, 1, 512)    0           ['add_51[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 512)          0           ['leaky_re_lu_103[0][0]']        \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 512)          262144      ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " latent_space_layer_norm (Batch  (None, 512)         2048        ['dense_18[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 50)           25650       ['latent_space_layer_norm[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_175 (Batch  (None, 50)          200         ['dense_19[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 50)           0           ['batch_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 25)           1275        ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_176 (Batch  (None, 25)          100         ['dense_20[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 25)           0           ['batch_normalization_176[0][0]']\n",
      "                                                                                                  \n",
      " classif (Dense)                (None, 22)           572         ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 91,481,061\n",
      "Trainable params: 91,452,399\n",
      "Non-trainable params: 28,662\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_classifier(len_vecteur=22)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d7d9eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnie = 'afro_americans'\n",
    "x_train = ethnies[ethnie][2] ; y_train = ethnies[ethnie][3]\n",
    "x_val   = ethnies[ethnie][4] ; y_val   = ethnies[ethnie][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98a11398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "137/137 [==============================] - 22s 143ms/step - loss: 4.4345 - categorical_accuracy: 0.0988 - val_loss: 4.2805 - val_categorical_accuracy: 0.0875\n",
      "Epoch 2/25\n",
      "137/137 [==============================] - 18s 129ms/step - loss: 3.8836 - categorical_accuracy: 0.1859 - val_loss: 3.8971 - val_categorical_accuracy: 0.1500\n",
      "Epoch 3/25\n",
      "137/137 [==============================] - 18s 129ms/step - loss: 3.5751 - categorical_accuracy: 0.2613 - val_loss: 3.2623 - val_categorical_accuracy: 0.3000\n",
      "Epoch 4/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 3.2607 - categorical_accuracy: 0.3417 - val_loss: 3.0160 - val_categorical_accuracy: 0.4000\n",
      "Epoch 5/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 2.9655 - categorical_accuracy: 0.4247 - val_loss: 2.8680 - val_categorical_accuracy: 0.4875\n",
      "Epoch 6/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 2.7214 - categorical_accuracy: 0.4873 - val_loss: 2.6857 - val_categorical_accuracy: 0.4750\n",
      "Epoch 7/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 2.4712 - categorical_accuracy: 0.5560 - val_loss: 2.6126 - val_categorical_accuracy: 0.5000\n",
      "Epoch 8/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 2.2486 - categorical_accuracy: 0.6154 - val_loss: 2.3374 - val_categorical_accuracy: 0.5625\n",
      "Epoch 9/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 1.9900 - categorical_accuracy: 0.6837 - val_loss: 2.1990 - val_categorical_accuracy: 0.5875\n",
      "Epoch 10/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 1.7501 - categorical_accuracy: 0.7463 - val_loss: 2.1869 - val_categorical_accuracy: 0.6125\n",
      "Epoch 11/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 1.5530 - categorical_accuracy: 0.7960 - val_loss: 2.2998 - val_categorical_accuracy: 0.5250\n",
      "Epoch 12/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 1.3527 - categorical_accuracy: 0.8490 - val_loss: 2.0089 - val_categorical_accuracy: 0.6750\n",
      "Epoch 13/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 1.2290 - categorical_accuracy: 0.8728 - val_loss: 2.0364 - val_categorical_accuracy: 0.6375\n",
      "Epoch 14/25\n",
      "137/137 [==============================] - 18s 129ms/step - loss: 1.0739 - categorical_accuracy: 0.9056 - val_loss: 1.9880 - val_categorical_accuracy: 0.6875\n",
      "Epoch 15/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 0.9802 - categorical_accuracy: 0.9246 - val_loss: 1.9604 - val_categorical_accuracy: 0.6625\n",
      "Epoch 16/25\n",
      "137/137 [==============================] - 18s 131ms/step - loss: 0.8853 - categorical_accuracy: 0.9372 - val_loss: 2.1497 - val_categorical_accuracy: 0.5875\n",
      "Epoch 17/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 0.8373 - categorical_accuracy: 0.9434 - val_loss: 1.8205 - val_categorical_accuracy: 0.6125\n",
      "Epoch 18/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 0.7427 - categorical_accuracy: 0.9606 - val_loss: 1.8059 - val_categorical_accuracy: 0.6500\n",
      "Epoch 19/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 0.6930 - categorical_accuracy: 0.9633 - val_loss: 1.6959 - val_categorical_accuracy: 0.6625\n",
      "Epoch 20/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 0.6591 - categorical_accuracy: 0.9601 - val_loss: 1.6879 - val_categorical_accuracy: 0.7125\n",
      "Epoch 21/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 0.6273 - categorical_accuracy: 0.9603 - val_loss: 1.7032 - val_categorical_accuracy: 0.6875\n",
      "Epoch 22/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 0.5931 - categorical_accuracy: 0.9631 - val_loss: 1.5855 - val_categorical_accuracy: 0.7000\n",
      "Epoch 23/25\n",
      "137/137 [==============================] - 18s 131ms/step - loss: 0.5672 - categorical_accuracy: 0.9642 - val_loss: 1.5903 - val_categorical_accuracy: 0.6750\n",
      "Epoch 24/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 0.5350 - categorical_accuracy: 0.9654 - val_loss: 1.7984 - val_categorical_accuracy: 0.6250\n",
      "Epoch 25/25\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 0.4784 - categorical_accuracy: 0.9785 - val_loss: 1.6053 - val_categorical_accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=25,\n",
    "                    validation_data=(x_val, y_val), shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bcc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=32, epochs=100, \n",
    "                    validation_data=(x_val, y_val), shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b942476",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnie = 'afro_americans'\n",
    "x_train = ethnies[ethnie][2] ; y_train = ethnies[ethnie][3]\n",
    "x_val   = ethnies[ethnie][4] ; y_val   = ethnies[ethnie][5]\n",
    "\n",
    "# Création du modèle\n",
    "model = create_hybride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "history = model.fit(x_train, {'recon_image': x_train, 'classif': y_train},\n",
    "                    validation_data=(x_val, {'recon_image': x_val, 'classif': y_val}),\n",
    "                    epochs=1000, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_autoencoder.predict(x_val)\n",
    "x_val_predict = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_latent = tf.keras.Model(inputs=model_autoencoder.input, outputs=model_autoencoder.get_layer('latent_space_layer_norm').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68025ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_latent.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1169e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "afro_americans_latent = get_latent.predict(x_val).reshape(x_val.shape[0], 512)\n",
    "caucasian_latent = get_latent.predict(ethnies['caucasians'][-2]).reshape(ethnies['caucasians'][-2].shape[0], 512)\n",
    "asians_latent = get_latent.predict(ethnies['asians'][-2]).reshape(ethnies['asians'][-2].shape[0], 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37931f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "afro_americans_latent.shape, caucasian_latent.shape, asians_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75adc1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le nombre de lignes et de colonnes\n",
    "rows = len(x_val)  # nombre d'images à afficher\n",
    "cols = 2  # 2 colonnes, une pour l'image et une pour sa prédiction\n",
    "\n",
    "fig, axes = plt.subplots(30, cols, figsize=(10, 80))\n",
    "\n",
    "# Afficher les images dans la grille avec des légendes\n",
    "for i in range(30):\n",
    "    # Afficher l'image de x_val\n",
    "    ax_val = axes[i, 0]\n",
    "    ax_val.imshow(x_val[i])\n",
    "    ax_val.set_title(f'image[{i}]')\n",
    "    ax_val.axis('off')\n",
    "    \n",
    "    # Afficher l'image de x_train\n",
    "    ax_train = axes[i, 1]\n",
    "    ax_train.imshow(x_val_predict[i])\n",
    "    ax_train.set_title(f'reconstruction[{i}]')\n",
    "    ax_train.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe1e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "rows = len(x_val)\n",
    "\n",
    "cpt_correct = 0\n",
    "for i in range(rows):\n",
    "    # distance pred à ground truth\n",
    "    correct_vector_distance = distance.euclidean(y_val[i], y_val_predict[i])\n",
    "    # distances entre la pred et tous les autres vecteurs\n",
    "    other_distances = [distance.euclidean(y_val[i], y_val[j]) for j in range(rows) if j != i]\n",
    "    #vérifie si la distance est bien la plus petite de toutes\n",
    "    is_correct_prediction = correct_vector_distance <= min(other_distances)\n",
    "    if is_correct_prediction:\n",
    "        cpt_correct += 1\n",
    "\n",
    "cpt_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def pca(dico_latent, ethnie):\n",
    "    scatters = []\n",
    "    pca = PCA(n_components=2)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for latent in dico_latent.keys():\n",
    "        latent_pca = pca.fit_transform(dico_latent[latent][0])\n",
    "        dico_latent[latent].append(latent_pca)  # ajout de latent_pca\n",
    "        scatter = plt.scatter(latent_pca[:, 0], latent_pca[:, 1], alpha=0.5, label=latent)\n",
    "        scatters.append(scatter)\n",
    "    plt.legend(handles=scatters)\n",
    "    plt.title(f'Projection ACP de l espace latent {ethnie}')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.show()\n",
    "\n",
    "    return dico_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_latent = {'afro_americans': [afro_americans_latent], \n",
    "               'caucasians': [caucasian_latent], \n",
    "               'asians': [asians_latent]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d880dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_latent = pca(dico_latent, \"afro_americans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_dispersion(latent_representations):\n",
    "    centroid = np.mean(latent_representations, axis=0)\n",
    "    distance_squared = np.sum((latent_representations - centroid)**2, axis = 1)\n",
    "    return np.mean(distance_squared)\n",
    "\n",
    "def comparaison_dispersion(dico_latent):\n",
    "    for ethnie in dico_latent.keys():\n",
    "        dispersion = calculate_mean_dispersion(dico_latent[ethnie][1])\n",
    "        print(f\"Moyenne des dispersions des espaces latents pour les individus {ethnie} : {dispersion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_dispersion(dico_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2b8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN-ORE",
   "language": "python",
   "name": "cnn-ore"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
