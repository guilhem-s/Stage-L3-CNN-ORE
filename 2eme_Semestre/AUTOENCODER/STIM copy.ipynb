{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from keras.models import load_model, Model\n",
    "from scipy.stats import gaussian_kde\n",
    "from keras import Input\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.layers import Conv2D, MaxPooling2D, Resizing, UpSampling2D, Dense, BatchNormalization, LeakyReLU, Add, Flatten, Reshape, add\n",
    "from keras.autoencoders import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.losses import MeanSquaredError, MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_to_array(generator):\n",
    "    # Initialiser une liste pour stocker les échantillons\n",
    "    num_samples = len(generator)\n",
    "    samples = []\n",
    "    # Itérer sur le générateur pour obtenir les échantillons\n",
    "    for i in range(num_samples):\n",
    "        batch = generator.next()\n",
    "        for image in batch[0]:\n",
    "            samples.append(image)  # Ajouter uniquement les données (ignorer les étiquettes)\n",
    "    return np.array(samples)\n",
    "\n",
    "def mean_cosinus_similarity(v1, v2):\n",
    "    cosinus_similarity = 0\n",
    "    nb_individus = v1.shape[0]\n",
    "    for i in range(nb_individus):\n",
    "        cosinus_similarity += np.dot(v1[i], v2[i]) / (np.linalg.norm(v1[i]) * np.linalg.norm(v2[i]))\n",
    "    return cosinus_similarity/nb_individus\n",
    "\n",
    "def calculate_mean_dispersion(latent_representations):\n",
    "    centroid = np.mean(latent_representations, axis=0)\n",
    "    distance_squared = np.sum((latent_representations - centroid)**2, axis = 1)\n",
    "    return np.mean(distance_squared)\n",
    "\n",
    "def comparaison_visages(asian, asian_predict, white, white_predict, ethnie):\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # Affichage des images du premier trainset\n",
    "    plt.subplot(2, 5, (1, 5))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('Caucasiens')\n",
    "    for i in range(5):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(white[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(2, 5, i + 6)\n",
    "        plt.imshow(white_predict[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    # Titre global\n",
    "    plt.suptitle(f'Comparaison des images d entrées et de sorties caucasiennes d espace latent {ethnie}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # Affichage des images du premier trainset\n",
    "    plt.subplot(2, 5, (1, 5))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('Asiatiques')\n",
    "    for i in range(5):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(asian[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(2, 5, i + 6)\n",
    "        plt.imshow(asian_predict[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    # Titre global\n",
    "    plt.suptitle('Comparaison des images d entrées et de sorties asiatiques')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def pca(latent_asian, latent_white, ethnie):\n",
    "    pca = PCA(n_components=2)\n",
    "    latent_pca_white = pca.fit_transform(latent_white)\n",
    "    latent_pca_asian = pca.fit_transform(latent_asian)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(latent_pca_white[:, 0], latent_pca_white[:, 1], color='r', alpha=0.5, label='white_predict')\n",
    "    scatter_b = plt.scatter(latent_pca_asian[:, 0], latent_pca_asian[:, 1], color='b', alpha=0.5, label='asian_predict')\n",
    "    plt.legend(handles=[scatter, scatter_b])\n",
    "    plt.title(f'Projection ACP de l espace latent {ethnie}')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.show()\n",
    "\n",
    "    return np.concatenate([latent_pca_white, latent_pca_asian], axis=0)\n",
    "\n",
    "\n",
    "def cosinus_similarity(asian_flatten, asian_predict_flatten, white_flatten, white_predict_flatten):\n",
    "    asian_cs = mean_cosinus_similarity(asian_flatten, asian_predict_flatten)\n",
    "    white_cs = mean_cosinus_similarity(white_flatten, white_predict_flatten)\n",
    "    print(f\"Moyenne des similarités cosinus pour les individus caucasiens : {white_cs}\")\n",
    "    print(f\"Moyenne des similarités cosinus pour les individus asiatiques : {asian_cs}\")\n",
    "    \n",
    "def comparaison_dispersion(latent_asian, latent_white):\n",
    "    asian_mean_dispersion = calculate_mean_dispersion(latent_asian)\n",
    "    white_mean_dispersion = calculate_mean_dispersion(latent_white)\n",
    "    print(f\"Moyenne des dispersions des espaces latents pour les individus caucasiens : {white_mean_dispersion}\")\n",
    "    print(f\"Moyenne des dispersions des espaces latents pour les individus asiatiques : {asian_mean_dispersion}\")\n",
    "\n",
    "def coef_bhattacharyya(latent_asian, latent_white):\n",
    "    normalize_a = tf.nn.l2_normalize(np.mean(latent_asian, axis=0),axis=0)        \n",
    "    normalize_b = tf.nn.l2_normalize(np.mean(latent_white, axis=0),axis=0)\n",
    "    return tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "\n",
    "def ssim_mean(ytrue, ypred, length):    \n",
    "    res = 0\n",
    "    for i in range(length):\n",
    "        res+=ssim(ytrue[i], ypred[i], data_range=ytrue[i].max() - ytrue[i].min(), multichannel=False)\n",
    "    \n",
    "    return res/length\n",
    "\n",
    "def structure_ssim(ytrue, ypred):\n",
    "    return ssim(ytrue, ypred, data_range=ytrue.max() - ytrue.min(), multichannel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencodeur(input_shape=(150, 150, 1), input_latent=512):\n",
    "\n",
    "    np.random.seed(42)\n",
    "    autoencoder=Sequential()\n",
    "\n",
    "    autoencoder.add(Conv2D(64, (3,3),activation='relu',padding='same', input_shape=(input_shape)))\n",
    "    autoencoder.add(MaxPooling2D((2,2), padding='same'))\n",
    "    autoencoder.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "    autoencoder.add(MaxPooling2D((2,2), padding='same'))\n",
    "    autoencoder.add(Conv2D(16, (3,3),activation='relu',padding='same'))\n",
    "    autoencoder.add(MaxPooling2D((2,2), padding='same'))\n",
    "    \n",
    "    autoencoder.add(Dense(input_latent, activation='relu', name = 'latent_space'))\n",
    "\n",
    "    autoencoder.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "    autoencoder.add(UpSampling2D((2,2)))\n",
    "    autoencoder.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "    autoencoder.add(UpSampling2D((2,2)))\n",
    "    autoencoder.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    autoencoder.add(UpSampling2D((2,2)))\n",
    "\n",
    "    autoencoder.add(Conv2D(1, (3,3), activation='relu', padding='same'))\n",
    "\n",
    "    autoencoder.add(Resizing(height=input_shape[0], width=input_shape[1], name='recon_image'))\n",
    "    autoencoder.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])\n",
    "\n",
    "    autoencoder.summary()\n",
    "    return autoencoder\n",
    "autoencoder = create_autoencodeur(input_shape=(300, 300, 1), input_latent=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder(input_shape=(150, 150, 1), input_latent=512):\n",
    "\n",
    "    input_img = Input(shape=input_shape)\n",
    "    filters = [16, 32, 64]\n",
    "    autoencoder=Sequential()\n",
    "\n",
    "    # Encoder\n",
    "    for i, filter in enumerate(filters):\n",
    "        autoencoder.add(Conv2D(filter, (3, 3), activation='relu', padding='same'))        \n",
    "        autoencoder.add(LeakyReLU(alpha=0.1))\n",
    "        autoencoder.add(BatchNormalization())\n",
    "        autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "        print(f'After {i+1} Conv2D: {autoencoder.output_shape}')\n",
    "\n",
    "    # Espace latent\n",
    "    #x = Flatten()(x)\n",
    "    autoencoder.add(Dense(input_latent, activation='relu', name='latent_space'))\n",
    "    autoencoder.add(BatchNormalization(name='latent_space_norm'))\n",
    "\n",
    "    # Décodeur\n",
    "    for i, filter in enumerate(reversed(filters)):\n",
    "        autoencoder.add(Conv2D(filter, (3, 3), activation='relu', padding='same'))        \n",
    "        autoencoder.add(LeakyReLU(alpha=0.1))\n",
    "        autoencoder.add(BatchNormalization())\n",
    "        autoencoder.add(UpSampling2D((2, 2)))\n",
    "        print(f'After {i+1} UpSampling2D: {autoencoder.output_shape}')\n",
    "    \n",
    "    autoencoder.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "    print(f'Decoded shape before resizing: {autoencoder.output_shape}')    \n",
    "    # Resize to match input shape\n",
    "    autoencoder.add(Resizing(height=input_shape[0], width=input_shape[1], name='final_output'))\n",
    "    print(f'Decoded shape after resizing: {autoencoder.output_shape}')\n",
    "\n",
    "    # Autoencoder autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=MeanAbsoluteError(), metrics=['accuracy'])\n",
    "    \n",
    "    # Display the model summary\n",
    "    autoencoder.summary()\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "autoencoder = create_autoencoder(input_shape=(300, 300, 1), input_latent=2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "trainset_white = train_datagen.flow_from_directory(\n",
    "    '../../Datasets/STIM_NB_LumNorm/Train',\n",
    "    classes=['Caucasiens'],\n",
    "    target_size=(300, 300), \n",
    "    batch_size=6, \n",
    "    class_mode='input',\n",
    "    color_mode='grayscale')\n",
    "testset_white = train_datagen.flow_from_directory(\n",
    "    '../../Datasets/STIM_NB_LumNorm/Test',\n",
    "    classes=['Caucasiens'],\n",
    "    target_size=(300, 300), \n",
    "    batch_size=6, \n",
    "    class_mode='input',\n",
    "    color_mode='grayscale')\n",
    "trainset_asian = train_datagen.flow_from_directory(\n",
    "    '../../Datasets/STIM_NB_LumNorm/Train',\n",
    "    classes=['Asiatiques'],\n",
    "    target_size=(300, 300),\n",
    "    batch_size=6,\n",
    "    class_mode='input',\n",
    "    color_mode='grayscale')\n",
    "testset_asian = train_datagen.flow_from_directory(\n",
    "    '../../Datasets/STIM_NB_LumNorm/Test',\n",
    "    classes=['Asiatiques'],\n",
    "    target_size=(300, 300),\n",
    "    batch_size=6,\n",
    "    class_mode='input',\n",
    "    color_mode='grayscale')\n",
    "trainset_mixed = train_datagen.flow_from_directory(\n",
    "    '../../Datasets/STIM_NB_LumNorm/',\n",
    "    classes=['Mixtes'],\n",
    "    target_size=(300, 300), \n",
    "    batch_size=10, \n",
    "    class_mode='input',\n",
    "    color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement réseau & Récupération de la couche latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=trainset_white, epochs=1000, validation_data=testset_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(testset_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6  # Number of images to display\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    # Afficher l'image originale\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(white[i].reshape(300, 300), cmap='gray')\n",
    "    plt.title(\"Original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(pred[i].reshape(300, 300), cmap='gray')\n",
    "    plt.title(\"Reconstruction\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_latent = keras.Model(inputs=model.input, outputs=model.get_layer('latent_space').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_asian = get_latent.predict(trainset_asian, verbose=0)\n",
    "latent_white = get_latent.predict(trainset_white, verbose=0)\n",
    "latent_asian = latent_asian.reshape(50, -1)\n",
    "latent_white = latent_white.reshape(50, -1)\n",
    "\n",
    "test_latent_asian = get_latent.predict(testset_asian, verbose=0)\n",
    "test_latent_white = get_latent.predict(testset_white, verbose=0)\n",
    "test_latent_asian = test_latent_asian.reshape(50, -1)\n",
    "test_latent_white = test_latent_white.reshape(50, -1)\n",
    "\n",
    "asian_predict = model.predict(trainset_asian, verbose=0).reshape(50,300,300)\n",
    "white_predict = model.predict(trainset_white, verbose=0).reshape(50,300,300)\n",
    "asian = generator_to_array(trainset_asian).reshape(50,300,300)\n",
    "white = generator_to_array(trainset_white).reshape(50,300,300)\n",
    "\n",
    "asian_predict_flatten = asian_predict.reshape(50, -1)\n",
    "white_predict_flatten = white_predict.reshape(50, -1)\n",
    "asian_flatten = asian.reshape(50, -1)\n",
    "white_flatten = white.reshape(50, -1)\n",
    "\n",
    "test_asian = generator_to_array(testset_asian).reshape(6, 300, 300)\n",
    "test_asian_predict = model.predict(testset_asian, verbose=0).reshape(6, 300, 300)\n",
    "test_white = generator_to_array(testset_white).reshape(6, 300, 300)\n",
    "test_white_predict = model.predict(testset_white, verbose=0).reshape(6, 300, 300)\n",
    "\n",
    "test_asian_predict_flatten = test_asian_predict.reshape(50, -1)\n",
    "test_white_predict_flatten = test_white_predict.reshape(50, -1)\n",
    "test_asian_flatten = test_asian.reshape(50, -1)\n",
    "test_white_flatten = test_white.reshape(50, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_visages(test_asian, test_asian_predict, test_white, test_white_predict, \"white\")\n",
    "latent_pca = pca(latent_asian, latent_white, \"white\")\n",
    "cosinus_similarity(asian_flatten, asian_predict_flatten, white_flatten, white_predict_flatten)\n",
    "print(f\"La similarité structurelle pour les caucasiens est de : {ssim_mean(white, white_predict, 50)}\")\n",
    "print(f\"La similarité structurelle pour les asiatiques est de : {ssim_mean(asian, asian_predict, 50)}\")\n",
    "comparaison_dispersion(latent_asian, latent_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envguilhem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
