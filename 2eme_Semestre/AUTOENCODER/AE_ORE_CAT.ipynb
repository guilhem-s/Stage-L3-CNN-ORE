{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.offsetbox as offsetbox\n",
    "\n",
    "import math\n",
    "import random\n",
    "from scipy.special import softmax\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigen_cam(model, img, layer_name = None, label_index=None):\n",
    "    \"\"\" Ce code permet est une implémentation de la méthode eigen_cam permettant de récupérer des cartes de saillance. \n",
    "        elles sont basées sur la décomposition de valeur de singulière. En gros on projette la sortie de la toute dernière couche de convolution \n",
    "        sur le premier vecteur singulier droit de l'équation. C'est la méthode avec laquelle j'ai récupéré les cartes qui sont dans ce dossier. \n",
    "        j'ai dû choisir cette méthode moins par choix que par praticité, en effet c'est une des rares à ne pas trop imposer de contraintes sur la couche \n",
    "        de sortie du réseau et donc la tâche effectuée. Puisque la couche de sortie de notre tâche d'identification est assez particulière et qu'elle n'effectue \n",
    "        pas une classification, c'était en fait la première méthode disponible. Donc, si on vous dit pendant votre soutenance que cette méthode \n",
    "        n'est pas adaptée (la SVD supposant la linéarité qui est une hypothèse baffouée en réseaux de neurones), vous pouvez répondre ça.  \"\"\"\n",
    "    # pour toute entrée, lui rajoute une dimension batch first si pas déjà présente:\n",
    "    img = tf.convert_to_tensor(img) if not tf.is_tensor(img) else img\n",
    "    img = tf.expand_dims(img, axis=0) if len(img.shape) == 3 else img # on travaille donc ici sur du (1, 224, 224, 3), càd du (batch, hauteur, largeur, canal)\n",
    "    img_height, img_width = img.shape[1], img.shape[2]\n",
    "    # extract the label_index of the last conv layer : \n",
    "    if layer_name is None:\n",
    "        for layer in reversed(model.layers):\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                layer_name = layer.name\n",
    "                break\n",
    "        if layer_name is None:\n",
    "            raise ValueError(\"Aucune couche de convolution trouvée dans le modèle.\")\n",
    "\n",
    "    layer = model.get_layer(layer_name).output\n",
    "    activation_model = tf.keras.Model(inputs = model.input, outputs = [model.output, layer])\n",
    "    \n",
    "    # 1°) Forward pass pour obtenir preds et activations de la layer\n",
    "    preds, feature = activation_model(img)\n",
    "\n",
    "    # 2°) décomposition en valeur singulière\n",
    "    s, u, v = tf.linalg.svd(feature, full_matrices = True)\n",
    "    vT = tf.transpose(v, [0, 1, 3, 2])\n",
    "\n",
    "    # 3°) Calcul de la carte CAM : \n",
    "    # On multiplie d'abord s par vT : s est scalaire pour chaque composante singulière, cela revient à une multiplication element-wise\n",
    "    scaled_vT = s[..., 0, None, None] * vT[..., 0, None, :]\n",
    "    # Ensuite, on fait une unique multiplication matricielle avec u\n",
    "    eigen_cam = tf.linalg.matmul(u[..., 0, None], scaled_vT)\n",
    "\n",
    "    # 4°) On somme sur l'axe canal \n",
    "    eigen_cam = tf.reduce_sum(eigen_cam, axis = -1, keepdims = True)\n",
    "\n",
    "    # 5°) Resize à l'espace (i,j) de l'image et normalisation\n",
    "    eigen_cam = tf.image.resize(eigen_cam, (img_height, img_width))\n",
    "    eigen_cam_min, eigen_cam_max = tf.reduce_min(eigen_cam), tf.reduce_max(eigen_cam)\n",
    "    eigen_cam = (eigen_cam - eigen_cam_min) / (eigen_cam_max - eigen_cam_min)\n",
    "   \n",
    "    eigen_cam = tf.squeeze(eigen_cam, axis = 0)\n",
    "    return eigen_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder(input_latent, shape):\n",
    "    input_img = tf.keras.Input(shape=shape)\n",
    "    # Feature extractor (encoder)\n",
    "    x = tf.keras.layers.BatchNormalization()(input_img)\n",
    "    x = tf.keras.layers.Conv2D(8, kernel_size=11, padding='same', activation='relu', use_bias=False)(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(16, kernel_size=5, activation='relu',padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu',padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu',padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu',padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu',padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Espace latent\n",
    "    encoded = x\n",
    "    latent_space_layer = tf.keras.layers.Dense(units=1*1*input_latent)(encoded)\n",
    "    latent_space_layer_norm = tf.keras.layers.BatchNormalization(name='latent_space_norm')(latent_space_layer)\n",
    "    \n",
    "    # Feature redear (decoder)\n",
    "    x_recon = tf.keras.layers.Reshape(target_shape=(1,1,input_latent))(latent_space_layer_norm)\n",
    "    x_recon = tf.keras.layers.Conv2DTranspose(64, kernel_size=5, activation='relu', strides=(2, 2), padding='same', use_bias=False)(x_recon)\n",
    "    x_recon = tf.keras.layers.BatchNormalization()(x_recon)\n",
    "    x_recon = tf.keras.layers.Conv2DTranspose(64, kernel_size=5, activation='relu', padding='same', use_bias=False)(x_recon)\n",
    "    x_recon = tf.keras.layers.BatchNormalization()(x_recon)\n",
    "    x_recon = tf.keras.layers.Conv2DTranspose(32, kernel_size=5, activation='relu', strides=(2, 2), padding='same', use_bias=False)(x_recon)\n",
    "    x_recon = tf.keras.layers.BatchNormalization()(x_recon)\n",
    "    x_recon = tf.keras.layers.Conv2DTranspose(32, kernel_size=5, activation='relu', padding='same', use_bias=False)(x_recon)\n",
    "    x_recon = tf.keras.layers.BatchNormalization()(x_recon)\n",
    "    x_recon = tf.keras.layers.Conv2DTranspose(16, kernel_size=5, activation='relu', strides=(2, 2), padding='same', use_bias=False)(x_recon)\n",
    "    x_recon = tf.keras.layers.BatchNormalization()(x_recon)\n",
    "    x_recon = tf.keras.layers.Conv2DTranspose(8, kernel_size=5, activation='relu', strides=(2, 2), padding='same', use_bias=False)(x_recon)\n",
    "    x_recon = tf.keras.layers.BatchNormalization()(x_recon)\n",
    "    x_recon = tf.keras.layers.Conv2DTranspose(1, kernel_size=11, activation='sigmoid', padding='same')(x_recon)  \n",
    "    x_recon = tf.keras.layers.Resizing(28,28)(x_recon)\n",
    "\n",
    "    # Classifier branch -> pour Théo uniquement, si assez de temps disponible\n",
    "    # classifier = tf.keras.layers.Dense(10, activation='softmax')(latent_space_layer_norm)\n",
    "\n",
    "    # Full model\n",
    "    model = tf.keras.Model(inputs=input_img, outputs=[x_recon])\n",
    "    # model = tf.keras.Model(inputs=input_img, outputs=[x_recon, classifier]) -> pour Théo uniquement, si assez de temps disponible\n",
    "    model.compile(optimizer='SGD', loss=['mse'], metrics=['mae'])\n",
    "    # model.compile(optimizer='SGD', loss=['mse', 'categorical_crossentropy'], metrics=['mae', 'accuracy']) -> pour Théo uniquement, si assez de temps disponible\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12287 images belonging to 1 classes.\n",
      "Found 12278 images belonging to 1 classes.\n",
      "Found 24565 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "dataset_white = train_datagen.flow_from_directory(\n",
    "    '../../Datasets_FairFace/train',\n",
    "    classes=['White'],\n",
    "    target_size=(224, 224), \n",
    "    batch_size=32, \n",
    "    class_mode='input')\n",
    "dataset_east_asian = train_datagen.flow_from_directory(\n",
    "    '../../Datasets_FairFace/train',\n",
    "    classes=['East Asian'],\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='input')\n",
    "dataset_mixed = train_datagen.flow_from_directory(\n",
    "    '../../Datasets_FairFace/train',\n",
    "    target_size=(224, 224), \n",
    "    batch_size=32, \n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 1)]     0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 224, 224, 1)      4         \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 8)       968       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 112, 112, 8)      32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 16)      3200      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 56, 56, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 32)        4608      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 56, 56, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 32)        9216      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 64)        18432     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 28, 28, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 64)        36864     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 12544)            50176     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                802880    \n",
      "                                                                 \n",
      " latent_space_norm (BatchNor  (None, 64)               256       \n",
      " malization)                                                     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 1, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 2, 2, 64)         102400    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 2, 2, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 2, 2, 64)         102400    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 2, 2, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 4, 4, 32)         51200     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 4, 4, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 4, 4, 32)         25600     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 4, 4, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 8, 8, 16)         12800     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 8, 8, 16)         64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 16, 16, 8)        3200      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 16, 16, 8)        32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 16, 16, 1)        969       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " resizing (Resizing)         (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,226,645\n",
      "Trainable params: 1,200,691\n",
      "Non-trainable params: 25,954\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1°) on définit le réseau en donnant un nom à la couche cachée dont on veut récupérer l'espace latent, par exemple : \n",
    "shape = (224,224,1)\n",
    "input_latent = 64 #nombre de dimensions de l'espace latent, celui dont on veut qu'il modélise le face space de Tim Valentine donc\n",
    "model = create_autoencoder(input_latent, shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle qui récupère la reconstruction de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2°) On définit un deuxième modèle dontla sortie s'arrête à la layer dont on veut récupérer la représentation, on fait ça par un : \n",
    "get_latent = keras.Model(inputs=model.input, outputs=model.get_layer('latent_space_norm').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3°) On entraîne le modèle : \n",
    "# cas 1, avec un autoencodeur : \n",
    "history = model.fit(x=dataset_white, y=dataset_white, validation_data=(dataset_white,dataset_white), epochs=30, batch_size=16) #adapter la taille de la batch_size à ce que peut accepter votre GPU\n",
    "# cas 2, avec un hybride : \n",
    "#history = model.fit(x_train, [x_train, y_train], validation_data=(x_test, [x_test, y_test]), epochs=30, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4°) On obtient des données que l'on met en entrée du réseau par la méthode predict:\n",
    "for i in range(30):\n",
    "    batch = dataset_east_asian.next()\n",
    "    images_batch = batch[0]\n",
    "    \n",
    "latent_representations = get_latent.predict(images_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on le plot par PCA car le nombre de dimensions de cet espace est trop grand pour être affiché, à moins d'avoir choisi input_latent = 2 plus haut\n",
    "pca = PCA(n_components=2)\n",
    "latent_pca = pca.fit_transform(latent_representations)\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(latent_pca[:, 0], latent_pca[:, 1], c=np.argmax(y_test, axis=1), cmap='viridis', alpha=0.5)\n",
    "plt.colorbar(scatter, ticks=range(10))\n",
    "plt.title('PCA Projection of the Latent Space')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n",
    "# Note n°2 : cela présuppose d'avoir pû importer toute les données en même temps dans votre RAM, ce qui sera impossible avec le dataset VGG, donc il vaut mieux prendre fairface. Si nécessaire, pensez à importer les données avec un seul canal de couleur (donc en noir et blanc) et en (224,224) voire moins (par exemple 160,160). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envguilhem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
